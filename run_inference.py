#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TripoSGæ¨ç†è„šæœ¬ - ä½¿ç”¨æœ¬åœ°é¢„è®­ç»ƒæ¨¡å‹
"""

import argparse
import os
import sys
from glob import glob
from typing import Any, Union
from pathlib import Path

import numpy as np
import torch
import trimesh
from PIL import Image

# æ·»åŠ scriptsç›®å½•åˆ°è·¯å¾„
scripts_dir = Path(__file__).parent / "scripts"
sys.path.append(str(scripts_dir))

from triposg.pipelines.pipeline_triposg import TripoSGPipeline
from scripts.image_process import prepare_image
from scripts.briarmbg import BriaRMBG

import pymeshlab


@torch.no_grad()
def run_triposg(
    pipe: Any,
    image_input: Union[str, Image.Image],
    rmbg_net: Any,
    seed: int,
    num_inference_steps: int = 50,
    guidance_scale: float = 7.0,
    faces: int = -1,
) -> trimesh.Scene:

    img_pil = prepare_image(image_input, bg_color=np.array([1.0, 1.0, 1.0]), rmbg_net=rmbg_net)

    outputs = pipe(
        image=img_pil,
        generator=torch.Generator(device=pipe.device).manual_seed(seed),
        num_inference_steps=num_inference_steps,
        guidance_scale=guidance_scale,
    ).samples[0]
    mesh = trimesh.Trimesh(outputs[0].astype(np.float32), np.ascontiguousarray(outputs[1]))

    if faces > 0:
        mesh = simplify_mesh(mesh, faces)

    return mesh

def mesh_to_pymesh(vertices, faces):
    mesh = pymeshlab.Mesh(vertex_matrix=vertices, face_matrix=faces)
    ms = pymeshlab.MeshSet()
    ms.add_mesh(mesh)
    return ms

def pymesh_to_trimesh(mesh):
    verts = mesh.vertex_matrix()
    faces = mesh.face_matrix()
    return trimesh.Trimesh(vertices=verts, faces=faces)

def simplify_mesh(mesh: trimesh.Trimesh, n_faces):
    if mesh.faces.shape[0] > n_faces:
        ms = mesh_to_pymesh(mesh.vertices, mesh.faces)
        ms.meshing_merge_close_vertices()
        ms.meshing_decimation_quadric_edge_collapse(targetfacenum = n_faces)
        return pymesh_to_trimesh(ms.current_mesh())
    else:
        return mesh

def check_models():
    """æ£€æŸ¥é¢„è®­ç»ƒæ¨¡å‹æ˜¯å¦å­˜åœ¨"""
    triposg_weights_dir = Path("pretrained_weights/TripoSG")
    rmbg_weights_dir = Path("pretrained_weights/RMBG-1.4")
    
    if not triposg_weights_dir.exists():
        print(f"âŒ TripoSGæ¨¡å‹ä¸å­˜åœ¨: {triposg_weights_dir}")
        print("è¯·å…ˆè¿è¡Œ: python download_models.py")
        return False
    
    if not rmbg_weights_dir.exists():
        print(f"âŒ RMBGæ¨¡å‹ä¸å­˜åœ¨: {rmbg_weights_dir}")
        print("è¯·å…ˆè¿è¡Œ: python download_models.py")
        return False
    
    print("âœ… é¢„è®­ç»ƒæ¨¡å‹æ£€æŸ¥é€šè¿‡")
    return True

def main():
    """ä¸»å‡½æ•°"""
    device = "cuda" if torch.cuda.is_available() else "cpu"
    dtype = torch.float16 if device == "cuda" else torch.float32
    
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    print(f"æ•°æ®ç±»å‹: {dtype}")

    parser = argparse.ArgumentParser(description="TripoSGæ¨ç†è„šæœ¬")
    parser.add_argument("--image-input", type=str, required=True, help="è¾“å…¥å›¾åƒè·¯å¾„")
    parser.add_argument("--output-path", type=str, default="./output.glb", help="è¾“å‡ºGLBæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--seed", type=int, default=42, help="éšæœºç§å­")
    parser.add_argument("--num-inference-steps", type=int, default=50, help="æ¨ç†æ­¥æ•°")
    parser.add_argument("--guidance-scale", type=float, default=7.0, help="å¼•å¯¼å°ºåº¦")
    parser.add_argument("--faces", type=int, default=-1, help="ç®€åŒ–ç½‘æ ¼é¢æ•°(-1è¡¨ç¤ºä¸ç®€åŒ–)")
    args = parser.parse_args()

    # æ£€æŸ¥è¾“å…¥å›¾åƒ
    if not os.path.exists(args.image_input):
        print(f"âŒ è¾“å…¥å›¾åƒä¸å­˜åœ¨: {args.image_input}")
        return False

    # æ£€æŸ¥æ¨¡å‹
    if not check_models():
        return False

    # æ¨¡å‹è·¯å¾„
    triposg_weights_dir = "pretrained_weights/TripoSG"
    rmbg_weights_dir = "pretrained_weights/RMBG-1.4"

    try:
        print("\nğŸ”„ åˆå§‹åŒ–RMBGæ¨¡å‹...")
        # å°è¯•ç›´æ¥åŠ è½½model.pthæ–‡ä»¶
        from pathlib import Path

        model_path = Path(rmbg_weights_dir) / "model.pth"
        if model_path.exists():
            print(f"ä» {model_path} åŠ è½½æ¨¡å‹æƒé‡")
            rmbg_net = BriaRMBG()
            state_dict = torch.load(model_path, map_location=device)
            rmbg_net.load_state_dict(state_dict)
            rmbg_net = rmbg_net.to(device)
        else:
            # å›é€€åˆ°from_pretrainedæ–¹æ³•
            rmbg_net = BriaRMBG.from_pretrained(rmbg_weights_dir).to(device)

        rmbg_net.eval()
        print("âœ… RMBGæ¨¡å‹åŠ è½½æˆåŠŸ")

        print("\nğŸ”„ åˆå§‹åŒ–TripoSGç®¡é“...")
        pipe: TripoSGPipeline = TripoSGPipeline.from_pretrained(triposg_weights_dir).to(device, dtype)
        print("âœ… TripoSGç®¡é“åŠ è½½æˆåŠŸ")

        print(f"\nğŸ”„ å¼€å§‹æ¨ç†...")
        print(f"è¾“å…¥å›¾åƒ: {args.image_input}")
        print(f"è¾“å‡ºè·¯å¾„: {args.output_path}")
        print(f"æ¨ç†æ­¥æ•°: {args.num_inference_steps}")
        print(f"å¼•å¯¼å°ºåº¦: {args.guidance_scale}")
        print(f"éšæœºç§å­: {args.seed}")

        # è¿è¡Œæ¨ç†
        mesh = run_triposg(
            pipe,
            image_input=args.image_input,
            rmbg_net=rmbg_net,
            seed=args.seed,
            num_inference_steps=args.num_inference_steps,
            guidance_scale=args.guidance_scale,
            faces=args.faces,
        )

        # ä¿å­˜ç»“æœ
        print(f"\nğŸ’¾ ä¿å­˜ç½‘æ ¼åˆ°: {args.output_path}")
        mesh.export(args.output_path)
        
        print(f"âœ… æ¨ç†å®Œæˆ!")
        print(f"ç½‘æ ¼ä¿¡æ¯:")
        print(f"  - é¡¶ç‚¹æ•°: {len(mesh.vertices)}")
        print(f"  - é¢æ•°: {len(mesh.faces)}")
        print(f"  - è¾“å‡ºæ–‡ä»¶: {args.output_path}")
        
        return True

    except Exception as e:
        print(f"âŒ æ¨ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"\nç¨‹åºå‡ºé”™: {e}")
        sys.exit(1)
