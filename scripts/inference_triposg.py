import argparse
import os
import sys
from glob import glob
from typing import Any, Union

import numpy as np
import torch
import trimesh
from huggingface_hub import snapshot_download
from PIL import Image

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
script_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(script_dir)
sys.path.append(project_root)
sys.path.append(script_dir)

from triposg.pipelines.pipeline_triposg import TripoSGPipeline
from image_process import prepare_image
from briarmbg import BriaRMBG

import pymeshlab


def generate_uv_coordinates(vertices, method='smart'):
    """
    ä¸º3Dç½‘æ ¼ç”ŸæˆUVåæ ‡æ˜ å°„

    Args:
        vertices: ç½‘æ ¼é¡¶ç‚¹åæ ‡ (N, 3)
        method: UVæ˜ å°„æ–¹æ³• ('smart', 'spherical', 'cylindrical', 'planar')

    Returns:
        uv_coords: UVåæ ‡ (N, 2)
    """
    print(f"ğŸ—ºï¸ ç”ŸæˆUVåæ ‡æ˜ å°„ (æ–¹æ³•: {method})")

    if method == 'smart':
        return smart_uv_projection(vertices)
    elif method == 'spherical':
        return spherical_projection(vertices)
    elif method == 'cylindrical':
        return cylindrical_projection(vertices)
    elif method == 'planar':
        return planar_projection(vertices)
    else:
        print(f"âš ï¸ æœªçŸ¥çš„UVæ˜ å°„æ–¹æ³•: {method}ï¼Œä½¿ç”¨æ™ºèƒ½æŠ•å½±")
        return smart_uv_projection(vertices)


def smart_uv_projection(vertices):
    """æ™ºèƒ½UVæŠ•å½± - è‡ªåŠ¨é€‰æ‹©æœ€ä½³æŠ•å½±æ–¹æ³•"""
    center = vertices.mean(axis=0)
    centered = vertices - center

    # è®¡ç®—ç½‘æ ¼çš„å½¢çŠ¶ç‰¹å¾
    cov_matrix = np.cov(centered.T)
    eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)
    eigenvalues = np.sort(eigenvalues)[::-1]  # é™åºæ’åˆ—

    # è®¡ç®—å½¢çŠ¶æ¯”ç‡
    ratio1 = eigenvalues[1] / eigenvalues[0] if eigenvalues[0] > 1e-8 else 0
    ratio2 = eigenvalues[2] / eigenvalues[0] if eigenvalues[0] > 1e-8 else 0

    print(f"  å½¢çŠ¶åˆ†æ - æ¯”ç‡1: {ratio1:.3f}, æ¯”ç‡2: {ratio2:.3f}")

    # æ ¹æ®å½¢çŠ¶ç‰¹å¾é€‰æ‹©æŠ•å½±æ–¹æ³•
    if ratio1 > 0.7 and ratio2 > 0.7:
        # æ¥è¿‘çƒå½¢ - ä½¿ç”¨çƒé¢æŠ•å½±
        print("  æ£€æµ‹åˆ°çƒå½¢ç‰©ä½“ï¼Œä½¿ç”¨çƒé¢æŠ•å½±")
        return spherical_projection(vertices)
    elif ratio1 > 0.3 and ratio2 < 0.3:
        # æŸ±å½¢ç‰©ä½“ - ä½¿ç”¨æŸ±é¢æŠ•å½±
        print("  æ£€æµ‹åˆ°æŸ±å½¢ç‰©ä½“ï¼Œä½¿ç”¨æŸ±é¢æŠ•å½±")
        return cylindrical_projection(vertices)
    else:
        # æ‰å¹³ç‰©ä½“ - ä½¿ç”¨å¹³é¢æŠ•å½±
        print("  æ£€æµ‹åˆ°æ‰å¹³ç‰©ä½“ï¼Œä½¿ç”¨å¹³é¢æŠ•å½±")
        return planar_projection(vertices)


def spherical_projection(vertices):
    """æ”¹è¿›çš„çƒé¢æŠ•å½±UVæ˜ å°„"""
    # è®¡ç®—ç½‘æ ¼çš„ä¸»è½´æ–¹å‘
    center = vertices.mean(axis=0)
    centered = vertices - center

    # ä½¿ç”¨PCAæ‰¾åˆ°ä¸»è½´æ–¹å‘
    cov_matrix = np.cov(centered.T)
    eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)

    # æŒ‰ç‰¹å¾å€¼æ’åºï¼Œæœ€å¤§çš„ç‰¹å¾å‘é‡ä½œä¸ºä¸»è½´
    idx = np.argsort(eigenvalues)[::-1]
    eigenvectors = eigenvectors[:, idx]

    # å°†é¡¶ç‚¹è½¬æ¢åˆ°ä¸»è½´åæ ‡ç³»
    aligned_vertices = centered @ eigenvectors

    # æ ‡å‡†åŒ–åˆ°å•ä½çƒ
    max_dist = np.linalg.norm(aligned_vertices, axis=1).max()
    normalized = aligned_vertices / (max_dist + 1e-8)

    x, y, z = normalized[:, 0], normalized[:, 1], normalized[:, 2]

    # æ”¹è¿›çš„çƒé¢åæ ‡è®¡ç®—
    theta = np.arctan2(y, x)  # æ–¹ä½è§’ [-Ï€, Ï€]

    # è®¡ç®—æè§’ï¼Œé¿å…æ•°å€¼ä¸ç¨³å®š
    r_xy = np.sqrt(x**2 + y**2)
    phi = np.arctan2(r_xy, z)  # æè§’ [0, Ï€]

    # è½¬æ¢ä¸ºUVåæ ‡ï¼Œå¤„ç†æ¥ç¼é—®é¢˜
    u = (theta + np.pi) / (2 * np.pi)
    v = phi / np.pi

    # å¤„ç†æç‚¹é™„è¿‘çš„å¥‡å¼‚æ€§
    pole_threshold = 0.01
    north_pole_mask = (phi < pole_threshold)
    south_pole_mask = (phi > (np.pi - pole_threshold))

    if np.any(north_pole_mask):
        u[north_pole_mask] = 0.5
    if np.any(south_pole_mask):
        u[south_pole_mask] = 0.5

    # ç¡®ä¿UVåæ ‡åœ¨[0, 1]èŒƒå›´å†…
    u = np.clip(u, 0, 1)
    v = np.clip(v, 0, 1)

    return np.column_stack([u, v])


def cylindrical_projection(vertices):
    """æ”¹è¿›çš„æŸ±é¢æŠ•å½±UVæ˜ å°„"""
    center = vertices.mean(axis=0)
    centered = vertices - center

    # ä½¿ç”¨PCAæ‰¾åˆ°ä¸»è½´æ–¹å‘
    cov_matrix = np.cov(centered.T)
    eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)

    # æŒ‰ç‰¹å¾å€¼æ’åºï¼Œæœ€å¤§çš„ç‰¹å¾å‘é‡ä½œä¸ºæŸ±è½´
    idx = np.argsort(eigenvalues)[::-1]
    main_axis = eigenvectors[:, idx[0]]  # ä¸»è½´ä½œä¸ºæŸ±è½´

    # æ„å»ºæ—‹è½¬çŸ©é˜µï¼Œå°†ä¸»è½´å¯¹é½åˆ°Zè½´
    z_axis = np.array([0, 0, 1])
    if np.abs(np.dot(main_axis, z_axis)) < 0.999:
        # ä½¿ç”¨ç½—å¾·é‡Œæ ¼æ–¯æ—‹è½¬å…¬å¼
        v = np.cross(main_axis, z_axis)
        s = np.linalg.norm(v)
        c = np.dot(main_axis, z_axis)

        vx = np.array([[0, -v[2], v[1]], [v[2], 0, -v[0]], [-v[1], v[0], 0]])
        R = np.eye(3) + vx + vx @ vx * ((1 - c) / (s * s))
    else:
        R = np.eye(3)

    # åº”ç”¨æ—‹è½¬
    aligned_vertices = centered @ R.T

    x, y, z = aligned_vertices[:, 0], aligned_vertices[:, 1], aligned_vertices[:, 2]

    # æ”¹è¿›çš„æŸ±é¢åæ ‡è®¡ç®—
    theta = np.arctan2(y, x)  # æ–¹ä½è§’
    height = z  # é«˜åº¦

    # æ ‡å‡†åŒ–UVåæ ‡
    u = (theta + np.pi) / (2 * np.pi)

    # é«˜åº¦æ ‡å‡†åŒ–ï¼Œä½¿ç”¨æ›´ç¨³å®šçš„æ–¹æ³•
    height_range = height.max() - height.min()
    if height_range > 1e-8:
        v = (height - height.min()) / height_range
    else:
        v = np.full_like(height, 0.5)

    # ç¡®ä¿UVåæ ‡åœ¨[0, 1]èŒƒå›´å†…
    u = np.clip(u, 0, 1)
    v = np.clip(v, 0, 1)

    return np.column_stack([u, v])


def planar_projection(vertices, axis='auto'):
    """æ”¹è¿›çš„å¹³é¢æŠ•å½±UVæ˜ å°„"""
    center = vertices.mean(axis=0)
    centered = vertices - center

    # ä½¿ç”¨PCAæ‰¾åˆ°æœ€ä½³æŠ•å½±å¹³é¢
    cov_matrix = np.cov(centered.T)
    eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)

    # æŒ‰ç‰¹å¾å€¼æ’åº
    idx = np.argsort(eigenvalues)[::-1]
    eigenvectors = eigenvectors[:, idx]

    if axis == 'auto':
        # è‡ªåŠ¨é€‰æ‹©æœ€ä½³æŠ•å½±æ–¹å‘ï¼ˆæœ€å°ç‰¹å¾å€¼å¯¹åº”çš„æ–¹å‘ï¼‰
        u_axis = eigenvectors[:, 0]  # æœ€å¤§ç‰¹å¾å€¼å¯¹åº”çš„ç‰¹å¾å‘é‡
        v_axis = eigenvectors[:, 1]  # ä¸­ç­‰ç‰¹å¾å€¼å¯¹åº”çš„ç‰¹å¾å‘é‡
    else:
        # æ‰‹åŠ¨æŒ‡å®šæŠ•å½±è½´
        if axis == 'z':
            u_axis = np.array([1, 0, 0])
            v_axis = np.array([0, 1, 0])
        elif axis == 'y':
            u_axis = np.array([1, 0, 0])
            v_axis = np.array([0, 0, 1])
        else:  # x
            u_axis = np.array([0, 1, 0])
            v_axis = np.array([0, 0, 1])

    # æŠ•å½±åˆ°é€‰å®šçš„å¹³é¢
    u_coord = np.dot(centered, u_axis)
    v_coord = np.dot(centered, v_axis)

    # æ ‡å‡†åŒ–åˆ°[0, 1]ï¼Œå¤„ç†è¾¹ç•Œæƒ…å†µ
    u_range = u_coord.max() - u_coord.min()
    v_range = v_coord.max() - v_coord.min()

    if u_range > 1e-8:
        u = (u_coord - u_coord.min()) / u_range
    else:
        u = np.full_like(u_coord, 0.5)

    if v_range > 1e-8:
        v = (v_coord - v_coord.min()) / v_range
    else:
        v = np.full_like(v_coord, 0.5)

    # ç¡®ä¿UVåæ ‡åœ¨[0, 1]èŒƒå›´å†…
    u = np.clip(u, 0, 1)
    v = np.clip(v, 0, 1)

    return np.column_stack([u, v])


@torch.no_grad()
def run_triposg(
    pipe: Any,
    image_input: Union[str, Image.Image],
    rmbg_net: Any,
    seed: int,
    num_inference_steps: int = 50,
    guidance_scale: float = 7.0,
    faces: int = -1,
    generate_uv: bool = False,
    uv_method: str = 'smart',
) -> trimesh.Scene:

    img_pil = prepare_image(image_input, bg_color=np.array([1.0, 1.0, 1.0]), rmbg_net=rmbg_net)

    outputs = pipe(
        image=img_pil,
        generator=torch.Generator(device=pipe.device).manual_seed(seed),
        num_inference_steps=num_inference_steps,
        guidance_scale=guidance_scale,
    ).samples[0]

    # åˆ›å»ºåŸºç¡€ç½‘æ ¼
    vertices = outputs[0].astype(np.float32)
    faces = np.ascontiguousarray(outputs[1])

    # ç”ŸæˆUVåæ ‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if generate_uv:
        print("ğŸ—ºï¸ ä¸ºç½‘æ ¼ç”ŸæˆUVåæ ‡æ˜ å°„...")
        uv_coords = generate_uv_coordinates(vertices, method=uv_method)

        # åˆ›å»ºå¸¦UVåæ ‡çš„ç½‘æ ¼
        mesh = trimesh.Trimesh(vertices=vertices, faces=faces)

        # æ·»åŠ UVåæ ‡åˆ°ç½‘æ ¼çš„è§†è§‰å±æ€§
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„ç™½è‰²æè´¨ä½œä¸ºå ä½ç¬¦
        material = trimesh.visual.material.SimpleMaterial(
            diffuse=[255, 255, 255, 255]  # ç™½è‰²æè´¨
        )

        # åˆ›å»ºçº¹ç†è§†è§‰å¯¹è±¡
        texture_visual = trimesh.visual.TextureVisuals(
            uv=uv_coords,
            material=material
        )

        mesh.visual = texture_visual
        print(f"âœ… UVåæ ‡ç”Ÿæˆå®Œæˆ - é¡¶ç‚¹æ•°: {len(vertices)}, UVåæ ‡æ•°: {len(uv_coords)}")
    else:
        # åˆ›å»ºä¸å¸¦UVåæ ‡çš„ç½‘æ ¼
        mesh = trimesh.Trimesh(vertices, faces)

    # ç½‘æ ¼ç®€åŒ–ï¼ˆå¦‚æœæŒ‡å®šäº†ç›®æ ‡é¢æ•°ï¼‰
    if isinstance(faces, int) and faces > 0:
        print(f"ğŸ”§ ç®€åŒ–ç½‘æ ¼åˆ° {faces} ä¸ªé¢...")
        mesh = simplify_mesh(mesh, faces)

    return mesh

def mesh_to_pymesh(vertices, faces):
    mesh = pymeshlab.Mesh(vertex_matrix=vertices, face_matrix=faces)
    ms = pymeshlab.MeshSet()
    ms.add_mesh(mesh)
    return ms

def pymesh_to_trimesh(mesh):
    verts = mesh.vertex_matrix()#.tolist()
    faces = mesh.face_matrix()#.tolist()
    return trimesh.Trimesh(vertices=verts, faces=faces)  #, vID, fID

def simplify_mesh(mesh: trimesh.Trimesh, n_faces):
    """ç®€åŒ–ç½‘æ ¼ï¼Œä¿æŒUVåæ ‡ä¿¡æ¯"""
    if mesh.faces.shape[0] > n_faces:
        # ä¿å­˜åŸå§‹çš„è§†è§‰å±æ€§
        original_visual = mesh.visual if hasattr(mesh, 'visual') else None

        # ç®€åŒ–ç½‘æ ¼å‡ ä½•
        ms = mesh_to_pymesh(mesh.vertices, mesh.faces)
        ms.meshing_merge_close_vertices()
        ms.meshing_decimation_quadric_edge_collapse(targetfacenum = n_faces)
        simplified_mesh = pymesh_to_trimesh(ms.current_mesh())

        # å¦‚æœåŸå§‹ç½‘æ ¼æœ‰UVåæ ‡ï¼Œéœ€è¦é‡æ–°ç”Ÿæˆæˆ–æ’å€¼
        if original_visual and hasattr(original_visual, 'uv'):
            print("âš ï¸ ç½‘æ ¼ç®€åŒ–åé‡æ–°ç”ŸæˆUVåæ ‡...")
            # é‡æ–°ç”ŸæˆUVåæ ‡ï¼ˆå› ä¸ºé¡¶ç‚¹æ•°é‡å·²æ”¹å˜ï¼‰
            uv_coords = generate_uv_coordinates(simplified_mesh.vertices, method='smart')

            # æ¢å¤çº¹ç†è§†è§‰å±æ€§
            if hasattr(original_visual, 'material'):
                material = original_visual.material
            else:
                material = trimesh.visual.material.SimpleMaterial(
                    diffuse=[255, 255, 255, 255]
                )

            texture_visual = trimesh.visual.TextureVisuals(
                uv=uv_coords,
                material=material
            )
            simplified_mesh.visual = texture_visual

        return simplified_mesh
    else:
        return mesh

if __name__ == "__main__":
    device = "cuda"
    dtype = torch.float16

    parser = argparse.ArgumentParser(description="TripoSG 3Dæ¨¡å‹ç”Ÿæˆå·¥å…·")
    parser.add_argument("--image-input", type=str, required=True, help="è¾“å…¥å›¾åƒè·¯å¾„")
    parser.add_argument("--output-path", type=str, default="./output.glb", help="è¾“å‡ºGLBæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--seed", type=int, default=42, help="éšæœºç§å­")
    parser.add_argument("--num-inference-steps", type=int, default=50, help="æ¨ç†æ­¥æ•°")
    parser.add_argument("--guidance-scale", type=float, default=7.0, help="å¼•å¯¼å°ºåº¦")
    parser.add_argument("--faces", type=int, default=-1, help="ç›®æ ‡é¢æ•°ï¼ˆ-1è¡¨ç¤ºä¸ç®€åŒ–ï¼‰")

    # UVåæ ‡ç›¸å…³å‚æ•°
    parser.add_argument("--generate-uv", action="store_true", help="ç”ŸæˆUVåæ ‡æ˜ å°„")
    parser.add_argument("--uv-method", type=str, default="smart",
                       choices=['smart', 'spherical', 'cylindrical', 'planar'],
                       help="UVæ˜ å°„æ–¹æ³•")

    args = parser.parse_args()

    # download pretrained weights
    triposg_weights_dir = "pretrained_weights/TripoSG"
    rmbg_weights_dir = "pretrained_weights/RMBG-1.4"
    snapshot_download(repo_id="VAST-AI/TripoSG", local_dir=triposg_weights_dir)
    snapshot_download(repo_id="briaai/RMBG-1.4", local_dir=rmbg_weights_dir)

    # init rmbg model for background removal
    rmbg_net = BriaRMBG.from_pretrained(rmbg_weights_dir).to(device)
    rmbg_net.eval() 

    # init tripoSG pipeline
    pipe: TripoSGPipeline = TripoSGPipeline.from_pretrained(triposg_weights_dir).to(device, dtype)

    # run inference
    print(f"\nğŸ”„ å¼€å§‹3Dæ¨¡å‹ç”Ÿæˆ...")
    print(f"è¾“å…¥å›¾åƒ: {args.image_input}")
    print(f"è¾“å‡ºè·¯å¾„: {args.output_path}")
    print(f"æ¨ç†æ­¥æ•°: {args.num_inference_steps}")
    print(f"å¼•å¯¼å°ºåº¦: {args.guidance_scale}")
    print(f"éšæœºç§å­: {args.seed}")
    if args.generate_uv:
        print(f"UVæ˜ å°„æ–¹æ³•: {args.uv_method}")

    mesh = run_triposg(
        pipe,
        image_input=args.image_input,
        rmbg_net=rmbg_net,
        seed=args.seed,
        num_inference_steps=args.num_inference_steps,
        guidance_scale=args.guidance_scale,
        faces=args.faces,
        generate_uv=args.generate_uv,
        uv_method=args.uv_method,
    )

    # å¯¼å‡ºç½‘æ ¼
    mesh.export(args.output_path)

    print(f"\nâœ… 3Dæ¨¡å‹ç”Ÿæˆå®Œæˆ!")
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {args.output_path}")
    print(f"ğŸ“Š ç½‘æ ¼ä¿¡æ¯:")
    print(f"  - é¡¶ç‚¹æ•°: {len(mesh.vertices)}")
    print(f"  - é¢æ•°: {len(mesh.faces)}")

    if args.generate_uv and hasattr(mesh.visual, 'uv'):
        print(f"  - UVåæ ‡: âœ… å·²ç”Ÿæˆ ({len(mesh.visual.uv)} ä¸ª)")
        print(f"  - UVæ˜ å°„æ–¹æ³•: {args.uv_method}")
    else:
        print(f"  - UVåæ ‡: âŒ æœªç”Ÿæˆ")
