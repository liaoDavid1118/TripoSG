#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºäºå›¾åƒè¯­ä¹‰ç†è§£çš„çº¹ç†æ˜ å°„ç³»ç»Ÿ
è§£å†³çœ¼ç›è´´åˆ°è‚šå­ã€ç‰™é½¿è´´åˆ°è…¹éƒ¨ç­‰é”™ä½é—®é¢˜
"""

import argparse
import numpy as np
import trimesh
from PIL import Image, ImageEnhance, ImageFilter, ImageDraw
import cv2
from pathlib import Path
import sys

def analyze_image_semantics(image_path):
    """åˆ†æå›¾åƒçš„è¯­ä¹‰å†…å®¹ï¼Œè¯†åˆ«é¢éƒ¨ç‰¹å¾å’Œèº«ä½“éƒ¨ä½"""
    print("ğŸ” åˆ†æå›¾åƒè¯­ä¹‰å†…å®¹")
    
    # åŠ è½½å›¾åƒ
    if isinstance(image_path, str):
        img = Image.open(image_path)
    else:
        img = image_path
    
    if img.mode == 'RGBA':
        img = img.convert('RGB')
    elif img.mode != 'RGB':
        img = img.convert('RGB')
    
    img_array = np.array(img)
    h, w = img_array.shape[:2]
    
    # ä½¿ç”¨ç®€å•çš„é¢œè‰²å’Œä½ç½®åˆ†ææ¥è¯†åˆ«è¯­ä¹‰åŒºåŸŸ
    semantic_regions = {}
    
    # 1. é¢éƒ¨åŒºåŸŸæ£€æµ‹ï¼ˆåŸºäºä½ç½®å’Œé¢œè‰²ç‰¹å¾ï¼‰
    face_region = detect_face_region(img_array)
    semantic_regions['face'] = face_region
    
    # 2. çœ¼ç›åŒºåŸŸæ£€æµ‹
    eye_regions = detect_eye_regions(img_array, face_region)
    semantic_regions['eyes'] = eye_regions
    
    # 3. å˜´å·´åŒºåŸŸæ£€æµ‹
    mouth_region = detect_mouth_region(img_array, face_region)
    semantic_regions['mouth'] = mouth_region
    
    # 4. å¤´å‘åŒºåŸŸæ£€æµ‹
    hair_region = detect_hair_region(img_array, face_region)
    semantic_regions['hair'] = hair_region
    
    # 5. èº«ä½“åŒºåŸŸæ£€æµ‹
    body_region = detect_body_region(img_array, face_region)
    semantic_regions['body'] = body_region
    
    # 6. æ‰‹éƒ¨åŒºåŸŸæ£€æµ‹
    hand_regions = detect_hand_regions(img_array)
    semantic_regions['hands'] = hand_regions
    
    print("è¯­ä¹‰åŒºåŸŸæ£€æµ‹ç»“æœ:")
    for region_name, region_data in semantic_regions.items():
        if region_data is not None:
            print(f"  âœ… {region_name}: å·²æ£€æµ‹")
        else:
            print(f"  âŒ {region_name}: æœªæ£€æµ‹åˆ°")
    
    return semantic_regions

def detect_face_region(img_array):
    """æ£€æµ‹é¢éƒ¨åŒºåŸŸ"""
    h, w = img_array.shape[:2]
    
    # ç®€å•çš„é¢éƒ¨æ£€æµ‹ï¼šå‡è®¾é¢éƒ¨åœ¨å›¾åƒçš„ä¸­ä¸Šéƒ¨åˆ†
    # åŸºäºè‚¤è‰²æ£€æµ‹
    hsv = cv2.cvtColor(img_array, cv2.COLOR_RGB2HSV)
    
    # è‚¤è‰²èŒƒå›´ï¼ˆHSVï¼‰
    lower_skin = np.array([0, 20, 70])
    upper_skin = np.array([20, 255, 255])
    skin_mask = cv2.inRange(hsv, lower_skin, upper_skin)
    
    # å½¢æ€å­¦æ“ä½œæ¸…ç†å™ªå£°
    kernel = np.ones((5, 5), np.uint8)
    skin_mask = cv2.morphologyEx(skin_mask, cv2.MORPH_CLOSE, kernel)
    skin_mask = cv2.morphologyEx(skin_mask, cv2.MORPH_OPEN, kernel)
    
    # æ‰¾åˆ°æœ€å¤§çš„è‚¤è‰²åŒºåŸŸ
    contours, _ = cv2.findContours(skin_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if contours:
        # é€‰æ‹©æœ€å¤§çš„è½®å»“
        largest_contour = max(contours, key=cv2.contourArea)
        x, y, w_face, h_face = cv2.boundingRect(largest_contour)
        
        # æ‰©å±•é¢éƒ¨åŒºåŸŸ
        margin = 20
        x = max(0, x - margin)
        y = max(0, y - margin)
        w_face = min(w - x, w_face + 2 * margin)
        h_face = min(h - y, h_face + 2 * margin)
        
        return {
            'bbox': (x, y, w_face, h_face),
            'center': (x + w_face // 2, y + h_face // 2),
            'mask': skin_mask
        }
    
    # å¦‚æœè‚¤è‰²æ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ä½ç½®
    default_x, default_y = w // 4, h // 6
    default_w, default_h = w // 2, h // 3
    
    return {
        'bbox': (default_x, default_y, default_w, default_h),
        'center': (default_x + default_w // 2, default_y + default_h // 2),
        'mask': None
    }

def detect_eye_regions(img_array, face_region):
    """æ£€æµ‹çœ¼ç›åŒºåŸŸ"""
    if face_region is None:
        return None
    
    x, y, w, h = face_region['bbox']
    face_img = img_array[y:y+h, x:x+w]
    
    # è½¬æ¢ä¸ºç°åº¦å›¾
    gray = cv2.cvtColor(face_img, cv2.COLOR_RGB2GRAY)
    
    # ä½¿ç”¨Haarçº§è”æ£€æµ‹çœ¼ç›ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    # è¿™é‡Œä½¿ç”¨ç®€å•çš„ä½ç½®ä¼°è®¡
    eye_y = h // 4  # çœ¼ç›é€šå¸¸åœ¨é¢éƒ¨ä¸Š1/4å¤„
    eye_h = h // 6  # çœ¼ç›é«˜åº¦çº¦ä¸ºé¢éƒ¨é«˜åº¦çš„1/6
    
    # å·¦çœ¼
    left_eye_x = w // 6
    left_eye_w = w // 4
    
    # å³çœ¼
    right_eye_x = w * 2 // 3
    right_eye_w = w // 4
    
    return {
        'left_eye': {
            'bbox': (x + left_eye_x, y + eye_y, left_eye_w, eye_h),
            'center': (x + left_eye_x + left_eye_w // 2, y + eye_y + eye_h // 2)
        },
        'right_eye': {
            'bbox': (x + right_eye_x, y + eye_y, right_eye_w, eye_h),
            'center': (x + right_eye_x + right_eye_w // 2, y + eye_y + eye_h // 2)
        }
    }

def detect_mouth_region(img_array, face_region):
    """æ£€æµ‹å˜´å·´åŒºåŸŸ"""
    if face_region is None:
        return None
    
    x, y, w, h = face_region['bbox']
    
    # å˜´å·´é€šå¸¸åœ¨é¢éƒ¨ä¸‹1/3å¤„
    mouth_y = y + h * 2 // 3
    mouth_h = h // 6
    mouth_x = x + w // 4
    mouth_w = w // 2
    
    return {
        'bbox': (mouth_x, mouth_y, mouth_w, mouth_h),
        'center': (mouth_x + mouth_w // 2, mouth_y + mouth_h // 2)
    }

def detect_hair_region(img_array, face_region):
    """æ£€æµ‹å¤´å‘åŒºåŸŸ"""
    if face_region is None:
        return None
    
    h, w = img_array.shape[:2]
    face_x, face_y, face_w, face_h = face_region['bbox']
    
    # å¤´å‘åŒºåŸŸï¼šé¢éƒ¨ä¸Šæ–¹å’Œä¸¤ä¾§
    hair_x = max(0, face_x - face_w // 4)
    hair_y = 0
    hair_w = min(w - hair_x, face_w + face_w // 2)
    hair_h = face_y + face_h // 3
    
    return {
        'bbox': (hair_x, hair_y, hair_w, hair_h),
        'center': (hair_x + hair_w // 2, hair_y + hair_h // 2)
    }

def detect_body_region(img_array, face_region):
    """æ£€æµ‹èº«ä½“åŒºåŸŸ"""
    h, w = img_array.shape[:2]
    
    if face_region is None:
        # é»˜è®¤èº«ä½“åŒºåŸŸ
        body_x, body_y = 0, h // 3
        body_w, body_h = w, h * 2 // 3
    else:
        face_x, face_y, face_w, face_h = face_region['bbox']
        # èº«ä½“åŒºåŸŸï¼šé¢éƒ¨ä¸‹æ–¹
        body_x = 0
        body_y = face_y + face_h
        body_w = w
        body_h = h - body_y
    
    return {
        'bbox': (body_x, body_y, body_w, body_h),
        'center': (body_x + body_w // 2, body_y + body_h // 2)
    }

def detect_hand_regions(img_array):
    """æ£€æµ‹æ‰‹éƒ¨åŒºåŸŸ"""
    h, w = img_array.shape[:2]
    
    # ç®€å•ä¼°è®¡ï¼šæ‰‹éƒ¨é€šå¸¸åœ¨å›¾åƒçš„å·¦ä¸‹å’Œå³ä¸‹è§’
    hand_size = min(w, h) // 6
    
    left_hand = {
        'bbox': (0, h - hand_size, hand_size, hand_size),
        'center': (hand_size // 2, h - hand_size // 2)
    }
    
    right_hand = {
        'bbox': (w - hand_size, h - hand_size, hand_size, hand_size),
        'center': (w - hand_size // 2, h - hand_size // 2)
    }
    
    return {
        'left_hand': left_hand,
        'right_hand': right_hand
    }

def create_semantic_texture_mapping(mesh_vertices, mesh_faces, semantic_regions, original_image, texture_size=1024):
    """åŸºäºè¯­ä¹‰ç†è§£åˆ›å»ºçº¹ç†æ˜ å°„"""
    print("ğŸ§  åŸºäºè¯­ä¹‰ç†è§£åˆ›å»ºçº¹ç†æ˜ å°„")
    
    # åˆ†æ3Dæ¨¡å‹ç»“æ„
    orientation_info = detect_character_orientation(mesh_vertices)
    parts = segment_character_parts(mesh_vertices, orientation_info)
    
    # åˆ›å»ºçº¹ç†ç”»å¸ƒ
    texture = np.ones((texture_size, texture_size, 3), dtype=np.uint8) * 128
    
    # åŠ è½½åŸå§‹å›¾åƒ
    if isinstance(original_image, str):
        img = Image.open(original_image)
    else:
        img = original_image
    
    if img.mode == 'RGBA':
        img = img.convert('RGB')
    elif img.mode != 'RGB':
        img = img.convert('RGB')
    
    img_array = np.array(img)
    
    # è¯­ä¹‰æ˜ å°„è§„åˆ™ï¼šå°†å›¾åƒçš„è¯­ä¹‰åŒºåŸŸæ˜ å°„åˆ°3Dæ¨¡å‹çš„å¯¹åº”éƒ¨ä½
    semantic_mapping = {
        # é¢éƒ¨ç‰¹å¾ç²¾ç¡®æ˜ å°„
        'face': {
            'source_region': semantic_regions.get('face'),
            'target_uv': (0.0, 0.5, 0.5, 1.0),  # å·¦ä¸Šè§’
            'mesh_parts': ['face', 'head']
        },
        'eyes': {
            'source_region': semantic_regions.get('eyes'),
            'target_uv': (0.1, 0.4, 0.7, 0.9),  # é¢éƒ¨åŒºåŸŸå†…çš„çœ¼ç›ä½ç½®
            'mesh_parts': ['face']
        },
        'mouth': {
            'source_region': semantic_regions.get('mouth'),
            'target_uv': (0.15, 0.35, 0.5, 0.65),  # é¢éƒ¨åŒºåŸŸå†…çš„å˜´å·´ä½ç½®
            'mesh_parts': ['face']
        },
        'hair': {
            'source_region': semantic_regions.get('hair'),
            'target_uv': (0.0, 0.5, 0.8, 1.0),  # é¢éƒ¨ä¸Šæ–¹
            'mesh_parts': ['head', 'back_head']
        },
        'body': {
            'source_region': semantic_regions.get('body'),
            'target_uv': (0.0, 0.5, 0.0, 0.5),  # å·¦ä¸‹è§’
            'mesh_parts': ['chest', 'torso']
        },
        'hands': {
            'source_region': semantic_regions.get('hands'),
            'target_uv': (0.75, 1.0, 0.5, 1.0),  # å³ä¸Šè§’
            'mesh_parts': ['left_arm', 'right_arm']
        }
    }
    
    # åº”ç”¨è¯­ä¹‰æ˜ å°„
    for semantic_name, mapping_info in semantic_mapping.items():
        source_region = mapping_info['source_region']
        target_uv = mapping_info['target_uv']
        
        if source_region is None:
            continue
        
        # æå–æºå›¾åƒåŒºåŸŸ
        if semantic_name == 'face' and 'bbox' in source_region:
            x, y, w, h = source_region['bbox']
            src_region = img_array[y:y+h, x:x+w]
        elif semantic_name == 'eyes' and source_region:
            # åˆå¹¶å·¦å³çœ¼åŒºåŸŸ
            src_region = extract_eye_region(img_array, source_region)
        elif semantic_name == 'mouth' and 'bbox' in source_region:
            x, y, w, h = source_region['bbox']
            src_region = img_array[y:y+h, x:x+w]
        elif semantic_name == 'hair' and 'bbox' in source_region:
            x, y, w, h = source_region['bbox']
            src_region = img_array[y:y+h, x:x+w]
        elif semantic_name == 'body' and 'bbox' in source_region:
            x, y, w, h = source_region['bbox']
            src_region = img_array[y:y+h, x:x+w]
        elif semantic_name == 'hands' and source_region:
            # åˆå¹¶å·¦å³æ‰‹åŒºåŸŸ
            src_region = extract_hand_region(img_array, source_region)
        else:
            continue
        
        if src_region.size == 0:
            continue
        
        # è®¡ç®—ç›®æ ‡çº¹ç†åŒºåŸŸ
        u_min, u_max, v_min, v_max = target_uv
        dst_x1, dst_x2 = int(u_min * texture_size), int(u_max * texture_size)
        dst_y1, dst_y2 = int(v_min * texture_size), int(v_max * texture_size)
        
        # è°ƒæ•´å¤§å°å¹¶åº”ç”¨
        target_w, target_h = dst_x2 - dst_x1, dst_y2 - dst_y1
        if target_w > 0 and target_h > 0:
            resized = cv2.resize(src_region, (target_w, target_h), 
                               interpolation=cv2.INTER_LANCZOS4)
            
            # ç‰¹æ®Šå¤„ç†
            if semantic_name == 'face':
                resized = enhance_face_texture(resized)
            elif semantic_name == 'eyes':
                resized = enhance_eye_texture(resized)
            
            texture[dst_y1:dst_y2, dst_x1:dst_x2] = resized
    
    return Image.fromarray(texture)

def extract_eye_region(img_array, eye_regions):
    """æå–çœ¼ç›åŒºåŸŸ"""
    if 'left_eye' in eye_regions and 'right_eye' in eye_regions:
        left_bbox = eye_regions['left_eye']['bbox']
        right_bbox = eye_regions['right_eye']['bbox']
        
        # è®¡ç®—åŒ…å«ä¸¤åªçœ¼ç›çš„åŒºåŸŸ
        min_x = min(left_bbox[0], right_bbox[0])
        min_y = min(left_bbox[1], right_bbox[1])
        max_x = max(left_bbox[0] + left_bbox[2], right_bbox[0] + right_bbox[2])
        max_y = max(left_bbox[1] + left_bbox[3], right_bbox[1] + right_bbox[3])
        
        return img_array[min_y:max_y, min_x:max_x]
    
    return np.array([])

def extract_hand_region(img_array, hand_regions):
    """æå–æ‰‹éƒ¨åŒºåŸŸ"""
    if 'left_hand' in hand_regions:
        x, y, w, h = hand_regions['left_hand']['bbox']
        return img_array[y:y+h, x:x+w]
    
    return np.array([])

def enhance_face_texture(texture):
    """å¢å¼ºé¢éƒ¨çº¹ç†"""
    # å¢å¼ºå¯¹æ¯”åº¦å’Œç»†èŠ‚
    enhanced = cv2.convertScaleAbs(texture, alpha=1.2, beta=10)
    return enhanced

def enhance_eye_texture(texture):
    """å¢å¼ºçœ¼éƒ¨çº¹ç†"""
    # å¢å¼ºçœ¼éƒ¨ç»†èŠ‚
    enhanced = cv2.convertScaleAbs(texture, alpha=1.3, beta=5)
    return enhanced

# å¯¼å…¥ä¹‹å‰å®šä¹‰çš„å‡½æ•°
def detect_character_orientation(vertices):
    """æ£€æµ‹äººç‰©/åŠ¨ç‰©çš„æœå‘å’Œå§¿æ€"""
    center = vertices.mean(axis=0)
    centered = vertices - center
    
    cov_matrix = np.cov(centered.T)
    eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)
    idx = np.argsort(eigenvalues)[::-1]
    
    primary_axis = eigenvectors[:, idx[0]]
    secondary_axis = eigenvectors[:, idx[1]]
    tertiary_axis = eigenvectors[:, idx[2]]
    
    axes = [primary_axis, secondary_axis, tertiary_axis]
    y_components = [abs(axis[1]) for axis in axes]
    vertical_idx = np.argmax(y_components)
    
    if vertical_idx == 0:
        height_axis = primary_axis
        front_axis = secondary_axis
        side_axis = tertiary_axis
    elif vertical_idx == 1:
        height_axis = secondary_axis
        front_axis = primary_axis
        side_axis = tertiary_axis
    else:
        height_axis = tertiary_axis
        front_axis = primary_axis
        side_axis = secondary_axis
    
    if height_axis[1] < 0:
        height_axis = -height_axis
    
    return {
        'center': center,
        'height_axis': height_axis,
        'front_axis': front_axis,
        'side_axis': side_axis,
        'eigenvalues': eigenvalues[idx],
        'aspect_ratios': eigenvalues[idx] / eigenvalues[idx[0]]
    }

def segment_character_parts(vertices, orientation_info):
    """åˆ†å‰²è§’è‰²çš„èº«ä½“éƒ¨ä½"""
    center = orientation_info['center']
    centered = vertices - center
    
    height_proj = np.dot(centered, orientation_info['height_axis'])
    front_proj = np.dot(centered, orientation_info['front_axis'])
    side_proj = np.dot(centered, orientation_info['side_axis'])
    
    height_norm = (height_proj - height_proj.min()) / (height_proj.max() - height_proj.min() + 1e-8)
    front_norm = (front_proj - front_proj.min()) / (front_proj.max() - front_proj.min() + 1e-8)
    side_norm = (side_proj - side_proj.min()) / (side_proj.max() - side_proj.min() + 1e-8)
    
    distances = np.linalg.norm(centered, axis=1)
    dist_norm = distances / distances.max()
    
    parts = {}
    
    # åŸºæœ¬éƒ¨ä½åˆ†å‰²
    parts['head'] = height_norm > 0.8
    parts['face'] = parts['head'] & (front_norm > 0.6)
    parts['back_head'] = parts['head'] & (front_norm < 0.4)
    
    torso_mask = (height_norm >= 0.3) & (height_norm <= 0.8) & (dist_norm < 0.7)
    parts['torso'] = torso_mask
    parts['chest'] = torso_mask & (front_norm > 0.6)
    parts['back'] = torso_mask & (front_norm < 0.4)
    
    parts['left_arm'] = (side_norm < 0.2) & (height_norm > 0.4) & (dist_norm > 0.5)
    parts['right_arm'] = (side_norm > 0.8) & (height_norm > 0.4) & (dist_norm > 0.5)
    
    parts['legs'] = height_norm < 0.3
    
    return parts

def create_semantic_uv_mapping(vertices, parts, semantic_regions, texture_size=1024):
    """åŸºäºè¯­ä¹‰ç†è§£åˆ›å»ºUVæ˜ å°„"""
    print("ğŸ—ºï¸ åˆ›å»ºè¯­ä¹‰æ„ŸçŸ¥UVæ˜ å°„")

    uv_coords = np.zeros((len(vertices), 2))

    # ç²¾ç¡®çš„UVå¸ƒå±€ï¼Œç¡®ä¿é¢éƒ¨ç‰¹å¾æ­£ç¡®å¯¹åº”
    uv_layout = {
        'face': (0.0, 0.5, 0.5, 1.0),      # å·¦ä¸Šè§’ - é¢éƒ¨ä¸»åŒºåŸŸ
        'head': (0.0, 0.5, 0.5, 1.0),      # ä¸é¢éƒ¨å…±äº«åŒºåŸŸ
        'back_head': (0.5, 0.75, 0.75, 1.0), # å³ä¸Šå°å—
        'chest': (0.0, 0.5, 0.0, 0.5),     # å·¦ä¸‹è§’ - èƒ¸éƒ¨
        'torso': (0.0, 0.5, 0.0, 0.5),     # ä¸èƒ¸éƒ¨å…±äº«
        'back': (0.5, 1.0, 0.0, 0.5),      # å³ä¸‹è§’ - èƒŒéƒ¨
        'left_arm': (0.75, 1.0, 0.5, 0.75), # å³ä¸Šå°å—
        'right_arm': (0.75, 1.0, 0.25, 0.5), # å³ä¸­å°å—
        'legs': (0.5, 0.75, 0.5, 0.75),    # å³ä¸Šä¸­å—
    }

    # ä¸ºæ¯ä¸ªèº«ä½“éƒ¨ä½åˆ†é…UVåæ ‡
    for part_name, mask in parts.items():
        if not np.any(mask) or part_name not in uv_layout:
            continue

        # è·å–UVåŒºåŸŸ
        u_min, u_max, v_min, v_max = uv_layout[part_name]

        # ç®€å•çš„å¹³é¢æŠ•å½±åˆ°UVç©ºé—´
        part_vertices = vertices[mask]
        if len(part_vertices) > 0:
            # è®¡ç®—éƒ¨ä½çš„è¾¹ç•Œæ¡†
            min_coords = part_vertices.min(axis=0)
            max_coords = part_vertices.max(axis=0)
            ranges = max_coords - min_coords

            # é€‰æ‹©æœ€å¤§çš„ä¸¤ä¸ªç»´åº¦è¿›è¡ŒæŠ•å½±
            range_indices = np.argsort(ranges)[-2:]

            u_coord = part_vertices[:, range_indices[0]]
            v_coord = part_vertices[:, range_indices[1]]

            # æ ‡å‡†åŒ–åˆ°[0,1]
            if len(u_coord) > 0:
                u_range = u_coord.max() - u_coord.min()
                v_range = v_coord.max() - v_coord.min()

                if u_range > 1e-8:
                    u_norm = (u_coord - u_coord.min()) / u_range
                else:
                    u_norm = np.full_like(u_coord, 0.5)

                if v_range > 1e-8:
                    v_norm = (v_coord - v_coord.min()) / v_range
                else:
                    v_norm = np.full_like(v_coord, 0.5)

                # æ˜ å°„åˆ°åˆ†é…çš„UVåŒºåŸŸ
                u_final = u_min + u_norm * (u_max - u_min)
                v_final = v_min + v_norm * (v_max - v_min)

                uv_coords[mask, 0] = u_final
                uv_coords[mask, 1] = v_final

    return uv_coords

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="åŸºäºå›¾åƒè¯­ä¹‰ç†è§£çš„çº¹ç†æ˜ å°„")
    parser.add_argument("--mesh", type=str, required=True, help="è¾“å…¥3Dç½‘æ ¼æ–‡ä»¶")
    parser.add_argument("--image", type=str, required=True, help="è¾“å…¥å›¾åƒæ–‡ä»¶")
    parser.add_argument("--output", type=str, default="semantic_textured.glb", help="è¾“å‡ºæ–‡ä»¶")
    parser.add_argument("--texture-size", type=int, default=1024, help="çº¹ç†åˆ†è¾¨ç‡")
    parser.add_argument("--debug", action="store_true", help="ä¿å­˜è°ƒè¯•ä¿¡æ¯")

    args = parser.parse_args()

    try:
        # åŠ è½½ç½‘æ ¼
        print(f"ğŸ“‚ åŠ è½½3Dç½‘æ ¼: {args.mesh}")
        scene = trimesh.load(args.mesh)
        if isinstance(scene, trimesh.Scene):
            mesh = scene.geometry[list(scene.geometry.keys())[0]]
        else:
            mesh = scene
        print(f"âœ… ç½‘æ ¼åŠ è½½æˆåŠŸ - é¡¶ç‚¹: {len(mesh.vertices)}, é¢: {len(mesh.faces)}")

        # åˆ†æå›¾åƒè¯­ä¹‰
        semantic_regions = analyze_image_semantics(args.image)

        # æ£€æµ‹è§’è‰²æœå‘
        orientation_info = detect_character_orientation(mesh.vertices)

        # åˆ†å‰²èº«ä½“éƒ¨ä½
        parts = segment_character_parts(mesh.vertices, orientation_info)

        # åˆ›å»ºè¯­ä¹‰æ„ŸçŸ¥çš„çº¹ç†
        texture_image = create_semantic_texture_mapping(
            mesh.vertices, mesh.faces, semantic_regions, args.image, args.texture_size
        )

        # åˆ›å»ºUVæ˜ å°„
        uv_coords = create_semantic_uv_mapping(mesh.vertices, parts, semantic_regions, args.texture_size)

        # åº”ç”¨çº¹ç†
        material = trimesh.visual.material.PBRMaterial(
            baseColorTexture=texture_image,
            metallicFactor=0.1,
            roughnessFactor=0.8
        )

        texture_visual = trimesh.visual.TextureVisuals(
            uv=uv_coords,
            material=material
        )

        mesh.visual = texture_visual

        # ä¿å­˜ç»“æœ
        output_path = Path(args.output)
        mesh.export(args.output)

        # ä¿å­˜çº¹ç†å›¾åƒ
        texture_path = output_path.parent / f"{output_path.stem}_texture.png"
        texture_image.save(texture_path)

        # å¦‚æœå¯ç”¨è°ƒè¯•æ¨¡å¼ï¼Œä¿å­˜è¯­ä¹‰åˆ†æç»“æœ
        if args.debug:
            save_debug_info(args.image, semantic_regions, output_path.parent)

        print(f"\nâœ… è¯­ä¹‰çº¹ç†æ˜ å°„å®Œæˆ!")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {args.output}")
        print(f"ğŸ–¼ï¸ çº¹ç†æ–‡ä»¶: {texture_path}")

        return True

    except Exception as e:
        print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return False

def save_debug_info(image_path, semantic_regions, output_dir):
    """ä¿å­˜è°ƒè¯•ä¿¡æ¯"""
    print("ğŸ’¾ ä¿å­˜è°ƒè¯•ä¿¡æ¯")

    # åŠ è½½åŸå§‹å›¾åƒ
    img = Image.open(image_path)
    if img.mode == 'RGBA':
        img = img.convert('RGB')

    img_array = np.array(img)
    debug_img = img_array.copy()

    # åœ¨å›¾åƒä¸Šæ ‡æ³¨æ£€æµ‹åˆ°çš„åŒºåŸŸ
    colors = {
        'face': (255, 0, 0),      # çº¢è‰²
        'eyes': (0, 255, 0),      # ç»¿è‰²
        'mouth': (0, 0, 255),     # è“è‰²
        'hair': (255, 255, 0),    # é»„è‰²
        'body': (255, 0, 255),    # ç´«è‰²
        'hands': (0, 255, 255),   # é’è‰²
    }

    for region_name, region_data in semantic_regions.items():
        if region_data is None:
            continue

        color = colors.get(region_name, (128, 128, 128))

        if region_name in ['face', 'mouth', 'hair', 'body'] and 'bbox' in region_data:
            x, y, w, h = region_data['bbox']
            cv2.rectangle(debug_img, (x, y), (x + w, y + h), color, 2)
            cv2.putText(debug_img, region_name, (x, y - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

        elif region_name == 'eyes' and isinstance(region_data, dict):
            for eye_name, eye_data in region_data.items():
                if 'bbox' in eye_data:
                    x, y, w, h = eye_data['bbox']
                    cv2.rectangle(debug_img, (x, y), (x + w, y + h), color, 2)
                    cv2.putText(debug_img, eye_name, (x, y - 10),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)

        elif region_name == 'hands' and isinstance(region_data, dict):
            for hand_name, hand_data in region_data.items():
                if 'bbox' in hand_data:
                    x, y, w, h = hand_data['bbox']
                    cv2.rectangle(debug_img, (x, y), (x + w, y + h), color, 2)
                    cv2.putText(debug_img, hand_name, (x, y - 10),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)

    # ä¿å­˜è°ƒè¯•å›¾åƒ
    debug_path = output_dir / "semantic_analysis_debug.png"
    Image.fromarray(debug_img).save(debug_path)
    print(f"ğŸ” è¯­ä¹‰åˆ†æè°ƒè¯•å›¾åƒå·²ä¿å­˜: {debug_path}")

if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
