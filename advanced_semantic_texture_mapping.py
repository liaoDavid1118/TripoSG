#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é«˜çº§è¯­ä¹‰çº¹ç†æ˜ å°„ç³»ç»Ÿ
ä½¿ç”¨æ›´ç²¾ç¡®çš„å›¾åƒåˆ†æå’Œè¯­ä¹‰ç†è§£
"""

import argparse
import numpy as np
import trimesh
from PIL import Image, ImageEnhance, ImageFilter, ImageDraw
import cv2
from pathlib import Path
import sys

def advanced_face_detection(img_array):
    """ä½¿ç”¨æ›´é«˜çº§çš„é¢éƒ¨æ£€æµ‹æ–¹æ³•"""
    print("ğŸ¯ æ‰§è¡Œé«˜çº§é¢éƒ¨æ£€æµ‹")
    
    h, w = img_array.shape[:2]
    
    # æ–¹æ³•1: åŸºäºè‚¤è‰²çš„æ”¹è¿›æ£€æµ‹
    hsv = cv2.cvtColor(img_array, cv2.COLOR_RGB2HSV)
    lab = cv2.cvtColor(img_array, cv2.COLOR_RGB2LAB)
    
    # å¤šç§è‚¤è‰²èŒƒå›´
    skin_ranges = [
        # æµ…è‚¤è‰²
        ([0, 20, 70], [20, 255, 255]),
        # ä¸­ç­‰è‚¤è‰²
        ([0, 25, 80], [25, 255, 255]),
        # æ·±è‚¤è‰²
        ([0, 30, 60], [30, 255, 200])
    ]
    
    combined_mask = np.zeros((h, w), dtype=np.uint8)
    
    for lower, upper in skin_ranges:
        lower = np.array(lower)
        upper = np.array(upper)
        mask = cv2.inRange(hsv, lower, upper)
        combined_mask = cv2.bitwise_or(combined_mask, mask)
    
    # ä½¿ç”¨LABè‰²å½©ç©ºé—´è¿›ä¸€æ­¥ä¼˜åŒ–
    # è‚¤è‰²åœ¨LABç©ºé—´çš„ç‰¹å¾
    l_channel = lab[:, :, 0]
    a_channel = lab[:, :, 1]
    b_channel = lab[:, :, 2]
    
    # è‚¤è‰²é€šå¸¸æœ‰ç‰¹å®šçš„aå’Œbå€¼èŒƒå›´
    lab_mask = ((a_channel > 120) & (a_channel < 150) & 
                (b_channel > 120) & (b_channel < 150) &
                (l_channel > 50))
    
    combined_mask = cv2.bitwise_or(combined_mask, lab_mask.astype(np.uint8) * 255)
    
    # å½¢æ€å­¦æ“ä½œ
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))
    combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_CLOSE, kernel)
    combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_OPEN, kernel)
    
    # æ‰¾åˆ°æœ€å¤§çš„è¿é€šåŒºåŸŸ
    contours, _ = cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if contours:
        # é€‰æ‹©æœ€å¤§ä¸”æœ€æ¥è¿‘é¢éƒ¨æ¯”ä¾‹çš„è½®å»“
        best_contour = None
        best_score = 0
        
        for contour in contours:
            area = cv2.contourArea(contour)
            x, y, w_face, h_face = cv2.boundingRect(contour)
            
            # é¢éƒ¨æ¯”ä¾‹æ£€æŸ¥
            aspect_ratio = w_face / h_face if h_face > 0 else 0
            
            # ç†æƒ³çš„é¢éƒ¨å®½é«˜æ¯”çº¦ä¸º0.7-0.9
            ratio_score = 1.0 - abs(aspect_ratio - 0.8)
            
            # ä½ç½®å¾—åˆ†ï¼šé¢éƒ¨é€šå¸¸åœ¨å›¾åƒä¸ŠåŠéƒ¨åˆ†
            position_score = 1.0 - (y / h)
            
            # å¤§å°å¾—åˆ†ï¼šé¢éƒ¨åº”è¯¥å æ®åˆç†çš„å›¾åƒæ¯”ä¾‹
            size_ratio = area / (w * h)
            size_score = min(size_ratio * 10, 1.0) if size_ratio < 0.1 else max(1.0 - (size_ratio - 0.1) * 5, 0)
            
            # ç»¼åˆå¾—åˆ†
            total_score = ratio_score * 0.4 + position_score * 0.3 + size_score * 0.3
            
            if total_score > best_score and area > 1000:  # æœ€å°é¢ç§¯é˜ˆå€¼
                best_score = total_score
                best_contour = contour
        
        if best_contour is not None:
            x, y, w_face, h_face = cv2.boundingRect(best_contour)
            
            # æ‰©å±•é¢éƒ¨åŒºåŸŸ
            margin_x = int(w_face * 0.1)
            margin_y = int(h_face * 0.1)
            
            x = max(0, x - margin_x)
            y = max(0, y - margin_y)
            w_face = min(w - x, w_face + 2 * margin_x)
            h_face = min(h - y, h_face + 2 * margin_y)
            
            return {
                'bbox': (x, y, w_face, h_face),
                'center': (x + w_face // 2, y + h_face // 2),
                'confidence': best_score,
                'mask': combined_mask
            }
    
    # å¦‚æœæ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨æ™ºèƒ½é»˜è®¤ä½ç½®
    return get_smart_default_face_region(img_array)

def get_smart_default_face_region(img_array):
    """æ™ºèƒ½é»˜è®¤é¢éƒ¨åŒºåŸŸ"""
    h, w = img_array.shape[:2]
    
    # åˆ†æå›¾åƒçš„äº®åº¦åˆ†å¸ƒæ¥çŒœæµ‹é¢éƒ¨ä½ç½®
    gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
    
    # è®¡ç®—å›¾åƒä¸ŠåŠéƒ¨åˆ†çš„äº®åº¦åˆ†å¸ƒ
    upper_half = gray[:h//2, :]
    
    # æ‰¾åˆ°äº®åº¦è¾ƒé«˜çš„åŒºåŸŸï¼ˆé€šå¸¸æ˜¯é¢éƒ¨ï¼‰
    bright_threshold = np.percentile(upper_half, 70)
    bright_mask = upper_half > bright_threshold
    
    # æ‰¾åˆ°äº®åŒºåŸŸçš„ä¸­å¿ƒ
    y_coords, x_coords = np.where(bright_mask)
    
    if len(x_coords) > 0:
        center_x = int(np.mean(x_coords))
        center_y = int(np.mean(y_coords))
        
        # åŸºäºä¸­å¿ƒç‚¹åˆ›å»ºé¢éƒ¨åŒºåŸŸ
        face_w = min(w // 3, h // 3)
        face_h = int(face_w * 1.2)  # é¢éƒ¨é€šå¸¸æ¯”è¾ƒé«˜
        
        x = max(0, center_x - face_w // 2)
        y = max(0, center_y - face_h // 3)  # é¢éƒ¨ä¸­å¿ƒåä¸Š
        
        face_w = min(w - x, face_w)
        face_h = min(h - y, face_h)
        
    else:
        # æœ€åçš„é»˜è®¤ä½ç½®
        x, y = w // 4, h // 8
        face_w, face_h = w // 2, h // 2
    
    return {
        'bbox': (x, y, face_w, face_h),
        'center': (x + face_w // 2, y + face_h // 2),
        'confidence': 0.3,
        'mask': None
    }

def precise_facial_feature_detection(img_array, face_region):
    """ç²¾ç¡®çš„é¢éƒ¨ç‰¹å¾æ£€æµ‹"""
    print("ğŸ‘ï¸ æ‰§è¡Œç²¾ç¡®é¢éƒ¨ç‰¹å¾æ£€æµ‹")
    
    if face_region is None:
        return {}
    
    x, y, w, h = face_region['bbox']
    face_img = img_array[y:y+h, x:x+w]
    
    features = {}
    
    # çœ¼ç›æ£€æµ‹
    eyes = detect_eyes_precise(face_img, (x, y))
    if eyes:
        features['eyes'] = eyes
    
    # å˜´å·´æ£€æµ‹
    mouth = detect_mouth_precise(face_img, (x, y))
    if mouth:
        features['mouth'] = mouth
    
    # é¼»å­æ£€æµ‹
    nose = detect_nose_precise(face_img, (x, y))
    if nose:
        features['nose'] = nose
    
    # çœ‰æ¯›æ£€æµ‹
    eyebrows = detect_eyebrows_precise(face_img, (x, y))
    if eyebrows:
        features['eyebrows'] = eyebrows
    
    return features

def detect_eyes_precise(face_img, offset):
    """ç²¾ç¡®çš„çœ¼ç›æ£€æµ‹"""
    h, w = face_img.shape[:2]
    offset_x, offset_y = offset
    
    # çœ¼ç›é€šå¸¸åœ¨é¢éƒ¨ä¸Š1/3å¤„
    eye_region_y = h // 6
    eye_region_h = h // 3
    eye_region = face_img[eye_region_y:eye_region_y + eye_region_h, :]
    
    # è½¬æ¢ä¸ºç°åº¦å›¾
    gray = cv2.cvtColor(eye_region, cv2.COLOR_RGB2GRAY)
    
    # ä½¿ç”¨è¾¹ç¼˜æ£€æµ‹æ‰¾åˆ°çœ¼ç›è½®å»“
    edges = cv2.Canny(gray, 50, 150)
    
    # å½¢æ€å­¦æ“ä½œè¿æ¥è¾¹ç¼˜
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
    edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)
    
    # æ‰¾åˆ°è½®å»“
    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    eye_candidates = []
    
    for contour in contours:
        area = cv2.contourArea(contour)
        if area < 50 or area > 2000:  # è¿‡æ»¤ä¸åˆç†çš„å¤§å°
            continue
        
        x_eye, y_eye, w_eye, h_eye = cv2.boundingRect(contour)
        
        # çœ¼ç›çš„å®½é«˜æ¯”æ£€æŸ¥
        aspect_ratio = w_eye / h_eye if h_eye > 0 else 0
        if aspect_ratio < 1.2 or aspect_ratio > 3.0:  # çœ¼ç›é€šå¸¸æ˜¯æ¤­åœ†å½¢
            continue
        
        # è®¡ç®—åœ¨åŸå›¾ä¸­çš„åæ ‡
        abs_x = offset_x + x_eye
        abs_y = offset_y + eye_region_y + y_eye
        
        eye_candidates.append({
            'bbox': (abs_x, abs_y, w_eye, h_eye),
            'center': (abs_x + w_eye // 2, abs_y + h_eye // 2),
            'area': area
        })
    
    # é€‰æ‹©æœ€å¯èƒ½çš„ä¸¤åªçœ¼ç›
    if len(eye_candidates) >= 2:
        # æŒ‰é¢ç§¯æ’åºï¼Œé€‰æ‹©è¾ƒå¤§çš„ä¸¤ä¸ª
        eye_candidates.sort(key=lambda x: x['area'], reverse=True)
        
        # ç¡®ä¿ä¸¤åªçœ¼ç›åœ¨åˆç†çš„æ°´å¹³ä½ç½®
        eye1, eye2 = eye_candidates[0], eye_candidates[1]
        
        if eye1['center'][0] < eye2['center'][0]:
            left_eye, right_eye = eye1, eye2
        else:
            left_eye, right_eye = eye2, eye1
        
        return {
            'left_eye': left_eye,
            'right_eye': right_eye
        }
    
    # å¦‚æœæ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ä½ç½®
    return get_default_eye_positions(face_img, offset)

def get_default_eye_positions(face_img, offset):
    """é»˜è®¤çœ¼ç›ä½ç½®"""
    h, w = face_img.shape[:2]
    offset_x, offset_y = offset
    
    # æ ‡å‡†é¢éƒ¨æ¯”ä¾‹
    eye_y = offset_y + h // 3
    eye_h = h // 8
    eye_w = w // 6
    
    left_eye_x = offset_x + w // 4
    right_eye_x = offset_x + w * 3 // 4 - eye_w
    
    return {
        'left_eye': {
            'bbox': (left_eye_x, eye_y, eye_w, eye_h),
            'center': (left_eye_x + eye_w // 2, eye_y + eye_h // 2)
        },
        'right_eye': {
            'bbox': (right_eye_x, eye_y, eye_w, eye_h),
            'center': (right_eye_x + eye_w // 2, eye_y + eye_h // 2)
        }
    }

def detect_mouth_precise(face_img, offset):
    """ç²¾ç¡®çš„å˜´å·´æ£€æµ‹"""
    h, w = face_img.shape[:2]
    offset_x, offset_y = offset
    
    # å˜´å·´é€šå¸¸åœ¨é¢éƒ¨ä¸‹1/3å¤„
    mouth_region_y = h * 2 // 3
    mouth_region_h = h // 4
    mouth_region = face_img[mouth_region_y:mouth_region_y + mouth_region_h, :]
    
    # è½¬æ¢ä¸ºHSVï¼Œæ£€æµ‹çº¢è‰²åŒºåŸŸï¼ˆå˜´å”‡ï¼‰
    hsv = cv2.cvtColor(mouth_region, cv2.COLOR_RGB2HSV)
    
    # çº¢è‰²èŒƒå›´ï¼ˆå˜´å”‡é¢œè‰²ï¼‰
    lower_red1 = np.array([0, 50, 50])
    upper_red1 = np.array([10, 255, 255])
    lower_red2 = np.array([170, 50, 50])
    upper_red2 = np.array([180, 255, 255])
    
    mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
    mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
    red_mask = cv2.bitwise_or(mask1, mask2)
    
    # å½¢æ€å­¦æ“ä½œ
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 3))
    red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_CLOSE, kernel)
    
    # æ‰¾åˆ°è½®å»“
    contours, _ = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if contours:
        # é€‰æ‹©æœ€å¤§çš„è½®å»“
        largest_contour = max(contours, key=cv2.contourArea)
        x_mouth, y_mouth, w_mouth, h_mouth = cv2.boundingRect(largest_contour)
        
        # è®¡ç®—åœ¨åŸå›¾ä¸­çš„åæ ‡
        abs_x = offset_x + x_mouth
        abs_y = offset_y + mouth_region_y + y_mouth
        
        return {
            'bbox': (abs_x, abs_y, w_mouth, h_mouth),
            'center': (abs_x + w_mouth // 2, abs_y + h_mouth // 2)
        }
    
    # é»˜è®¤å˜´å·´ä½ç½®
    mouth_x = offset_x + w // 3
    mouth_y = offset_y + h * 3 // 4
    mouth_w = w // 3
    mouth_h = h // 12
    
    return {
        'bbox': (mouth_x, mouth_y, mouth_w, mouth_h),
        'center': (mouth_x + mouth_w // 2, mouth_y + mouth_h // 2)
    }

def detect_nose_precise(face_img, offset):
    """ç²¾ç¡®çš„é¼»å­æ£€æµ‹"""
    h, w = face_img.shape[:2]
    offset_x, offset_y = offset
    
    # é¼»å­é€šå¸¸åœ¨é¢éƒ¨ä¸­å¤®
    nose_x = offset_x + w // 3
    nose_y = offset_y + h // 2
    nose_w = w // 3
    nose_h = h // 4
    
    return {
        'bbox': (nose_x, nose_y, nose_w, nose_h),
        'center': (nose_x + nose_w // 2, nose_y + nose_h // 2)
    }

def detect_eyebrows_precise(face_img, offset):
    """ç²¾ç¡®çš„çœ‰æ¯›æ£€æµ‹"""
    h, w = face_img.shape[:2]
    offset_x, offset_y = offset
    
    # çœ‰æ¯›é€šå¸¸åœ¨çœ¼ç›ä¸Šæ–¹
    eyebrow_y = offset_y + h // 6
    eyebrow_h = h // 12
    
    left_eyebrow_x = offset_x + w // 6
    left_eyebrow_w = w // 4
    
    right_eyebrow_x = offset_x + w * 7 // 12
    right_eyebrow_w = w // 4
    
    return {
        'left_eyebrow': {
            'bbox': (left_eyebrow_x, eyebrow_y, left_eyebrow_w, eyebrow_h),
            'center': (left_eyebrow_x + left_eyebrow_w // 2, eyebrow_y + eyebrow_h // 2)
        },
        'right_eyebrow': {
            'bbox': (right_eyebrow_x, eyebrow_y, right_eyebrow_w, eyebrow_h),
            'center': (right_eyebrow_x + right_eyebrow_w // 2, eyebrow_y + eyebrow_h // 2)
        }
    }

def create_precise_texture_layout(original_image, face_region, facial_features, texture_size=1024):
    """åˆ›å»ºç²¾ç¡®çš„çº¹ç†å¸ƒå±€"""
    print("ğŸ¨ åˆ›å»ºç²¾ç¡®çº¹ç†å¸ƒå±€")
    
    # åŠ è½½åŸå§‹å›¾åƒ
    if isinstance(original_image, str):
        img = Image.open(original_image)
    else:
        img = original_image
    
    if img.mode == 'RGBA':
        img = img.convert('RGB')
    elif img.mode != 'RGB':
        img = img.convert('RGB')
    
    img_array = np.array(img)
    h, w = img_array.shape[:2]
    
    # åˆ›å»ºçº¹ç†ç”»å¸ƒ
    texture = np.ones((texture_size, texture_size, 3), dtype=np.uint8) * 128
    
    # ç²¾ç¡®çš„ç‰¹å¾æ˜ å°„
    if face_region and 'bbox' in face_region:
        face_x, face_y, face_w, face_h = face_region['bbox']
        
        # é¢éƒ¨ä¸»åŒºåŸŸ - å·¦ä¸Šè§’å¤§å—
        face_texture_region = (0, texture_size // 2, texture_size // 2, texture_size)
        apply_region_to_texture(img_array, (face_x, face_y, face_w, face_h), 
                              texture, face_texture_region, enhance_face=True)
        
        # ç²¾ç¡®æ”¾ç½®é¢éƒ¨ç‰¹å¾
        if 'eyes' in facial_features:
            eyes = facial_features['eyes']
            if 'left_eye' in eyes and 'right_eye' in eyes:
                # è®¡ç®—çœ¼ç›åŒºåŸŸ
                left_eye_bbox = eyes['left_eye']['bbox']
                right_eye_bbox = eyes['right_eye']['bbox']
                
                # åˆå¹¶çœ¼ç›åŒºåŸŸ
                min_x = min(left_eye_bbox[0], right_eye_bbox[0])
                min_y = min(left_eye_bbox[1], right_eye_bbox[1])
                max_x = max(left_eye_bbox[0] + left_eye_bbox[2], 
                           right_eye_bbox[0] + right_eye_bbox[2])
                max_y = max(left_eye_bbox[1] + left_eye_bbox[3], 
                           right_eye_bbox[1] + right_eye_bbox[3])
                
                eyes_region = (min_x, min_y, max_x - min_x, max_y - min_y)
                
                # çœ¼ç›æ”¾åœ¨é¢éƒ¨åŒºåŸŸçš„æ­£ç¡®ä½ç½®
                eye_texture_region = (texture_size // 8, texture_size * 3 // 8, 
                                    texture_size * 5 // 8, texture_size * 3 // 4)
                apply_region_to_texture(img_array, eyes_region, 
                                      texture, eye_texture_region, enhance_eyes=True)
        
        if 'mouth' in facial_features:
            mouth = facial_features['mouth']
            mouth_bbox = mouth['bbox']
            
            # å˜´å·´æ”¾åœ¨é¢éƒ¨åŒºåŸŸçš„ä¸‹æ–¹
            mouth_texture_region = (texture_size // 6, texture_size // 3, 
                                  texture_size // 2, texture_size * 5 // 8)
            apply_region_to_texture(img_array, mouth_bbox, 
                                  texture, mouth_texture_region, enhance_mouth=True)
    
    # èº«ä½“åŒºåŸŸ - å³ä¸‹è§’
    body_y_start = max(0, face_region['bbox'][1] + face_region['bbox'][3]) if face_region else h // 3
    body_region = (0, body_y_start, w, h - body_y_start)
    body_texture_region = (texture_size // 2, texture_size, 0, texture_size // 2)
    apply_region_to_texture(img_array, body_region, texture, body_texture_region)
    
    return Image.fromarray(texture)

def apply_region_to_texture(source_img, source_region, texture, texture_region, 
                          enhance_face=False, enhance_eyes=False, enhance_mouth=False):
    """å°†æºå›¾åƒåŒºåŸŸåº”ç”¨åˆ°çº¹ç†çš„æŒ‡å®šåŒºåŸŸ"""
    src_x, src_y, src_w, src_h = source_region
    tex_x1, tex_x2, tex_y1, tex_y2 = texture_region
    
    # ç¡®ä¿åæ ‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
    src_x = max(0, min(src_x, source_img.shape[1] - 1))
    src_y = max(0, min(src_y, source_img.shape[0] - 1))
    src_x2 = max(src_x + 1, min(src_x + src_w, source_img.shape[1]))
    src_y2 = max(src_y + 1, min(src_y + src_h, source_img.shape[0]))
    
    tex_x1 = max(0, min(tex_x1, texture.shape[1] - 1))
    tex_y1 = max(0, min(tex_y1, texture.shape[0] - 1))
    tex_x2 = max(tex_x1 + 1, min(tex_x2, texture.shape[1]))
    tex_y2 = max(tex_y1 + 1, min(tex_y2, texture.shape[0]))
    
    # æå–æºåŒºåŸŸ
    src_region = source_img[src_y:src_y2, src_x:src_x2]
    
    if src_region.size == 0:
        return
    
    # è°ƒæ•´å¤§å°
    target_w = tex_x2 - tex_x1
    target_h = tex_y2 - tex_y1
    
    if target_w > 0 and target_h > 0:
        resized = cv2.resize(src_region, (target_w, target_h), 
                           interpolation=cv2.INTER_LANCZOS4)
        
        # åº”ç”¨å¢å¼º
        if enhance_face:
            resized = cv2.convertScaleAbs(resized, alpha=1.15, beta=10)
        elif enhance_eyes:
            resized = cv2.convertScaleAbs(resized, alpha=1.25, beta=15)
        elif enhance_mouth:
            resized = cv2.convertScaleAbs(resized, alpha=1.1, beta=8)
        
        # åº”ç”¨åˆ°çº¹ç†
        texture[tex_y1:tex_y2, tex_x1:tex_x2] = resized

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="é«˜çº§è¯­ä¹‰çº¹ç†æ˜ å°„ç³»ç»Ÿ")
    parser.add_argument("--mesh", type=str, required=True, help="è¾“å…¥3Dç½‘æ ¼æ–‡ä»¶")
    parser.add_argument("--image", type=str, required=True, help="è¾“å…¥å›¾åƒæ–‡ä»¶")
    parser.add_argument("--output", type=str, default="advanced_semantic_textured.glb", help="è¾“å‡ºæ–‡ä»¶")
    parser.add_argument("--texture-size", type=int, default=1024, help="çº¹ç†åˆ†è¾¨ç‡")
    parser.add_argument("--debug", action="store_true", help="ä¿å­˜è°ƒè¯•ä¿¡æ¯")

    args = parser.parse_args()

    try:
        # åŠ è½½ç½‘æ ¼
        print(f"ğŸ“‚ åŠ è½½3Dç½‘æ ¼: {args.mesh}")
        scene = trimesh.load(args.mesh)
        if isinstance(scene, trimesh.Scene):
            mesh = scene.geometry[list(scene.geometry.keys())[0]]
        else:
            mesh = scene
        print(f"âœ… ç½‘æ ¼åŠ è½½æˆåŠŸ - é¡¶ç‚¹: {len(mesh.vertices)}, é¢: {len(mesh.faces)}")

        # åŠ è½½å’Œåˆ†æå›¾åƒ
        img = Image.open(args.image)
        if img.mode == 'RGBA':
            img = img.convert('RGB')
        img_array = np.array(img)

        # é«˜çº§é¢éƒ¨æ£€æµ‹
        face_region = advanced_face_detection(img_array)
        print(f"é¢éƒ¨æ£€æµ‹ç½®ä¿¡åº¦: {face_region.get('confidence', 0):.2f}")

        # ç²¾ç¡®é¢éƒ¨ç‰¹å¾æ£€æµ‹
        facial_features = precise_facial_feature_detection(img_array, face_region)

        # åˆ›å»ºç²¾ç¡®çº¹ç†å¸ƒå±€
        texture_image = create_precise_texture_layout(
            args.image, face_region, facial_features, args.texture_size
        )

        # åˆ›å»ºç®€å•çš„UVæ˜ å°„ï¼ˆå¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–ï¼‰
        uv_coords = create_simple_uv_mapping(mesh.vertices)

        # åº”ç”¨çº¹ç†
        material = trimesh.visual.material.PBRMaterial(
            baseColorTexture=texture_image,
            metallicFactor=0.1,
            roughnessFactor=0.8
        )

        texture_visual = trimesh.visual.TextureVisuals(
            uv=uv_coords,
            material=material
        )

        mesh.visual = texture_visual

        # ä¿å­˜ç»“æœ
        output_path = Path(args.output)
        mesh.export(args.output)

        # ä¿å­˜çº¹ç†å›¾åƒ
        texture_path = output_path.parent / f"{output_path.stem}_texture.png"
        texture_image.save(texture_path)

        # å¦‚æœå¯ç”¨è°ƒè¯•æ¨¡å¼ï¼Œä¿å­˜åˆ†æç»“æœ
        if args.debug:
            # åˆ†æ3Dæ¨¡å‹ç»“æ„
            mesh_analysis = analyze_3d_mesh_structure(mesh.vertices, mesh.faces)
            save_advanced_debug_info(img_array, face_region, facial_features, output_path.parent)
            save_3d_mesh_analysis(mesh, mesh_analysis, output_path.parent)

        print(f"\nâœ… é«˜çº§è¯­ä¹‰çº¹ç†æ˜ å°„å®Œæˆ!")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {args.output}")
        print(f"ğŸ–¼ï¸ çº¹ç†æ–‡ä»¶: {texture_path}")

        return True

    except Exception as e:
        print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return False

def create_simple_uv_mapping(vertices):
    """åˆ›å»ºç®€å•çš„UVæ˜ å°„"""
    # ä½¿ç”¨çƒé¢æŠ•å½±ä½œä¸ºåŸºç¡€
    center = vertices.mean(axis=0)
    centered = vertices - center

    # æ ‡å‡†åŒ–
    max_dist = np.linalg.norm(centered, axis=1).max()
    normalized = centered / (max_dist + 1e-8)

    x, y, z = normalized[:, 0], normalized[:, 1], normalized[:, 2]

    # çƒé¢åæ ‡
    theta = np.arctan2(y, x)
    phi = np.arccos(np.clip(z, -1, 1))

    # è½¬æ¢ä¸ºUVåæ ‡
    u = (theta + np.pi) / (2 * np.pi)
    v = phi / np.pi

    return np.column_stack([u, v])

def save_advanced_debug_info(img_array, face_region, facial_features, output_dir):
    """ä¿å­˜é«˜çº§è°ƒè¯•ä¿¡æ¯"""
    print("ğŸ’¾ ä¿å­˜é«˜çº§è°ƒè¯•ä¿¡æ¯")

    debug_img = img_array.copy()
    h, w = img_array.shape[:2]

    # åˆ›å»ºè¯¦ç»†çš„åˆ†ææŠ¥å‘Š
    analysis_report = []
    analysis_report.append("=== å›¾åƒè¯­ä¹‰åˆ†ææŠ¥å‘Š ===")
    analysis_report.append(f"å›¾åƒå°ºå¯¸: {w} x {h}")

    # æ ‡æ³¨é¢éƒ¨åŒºåŸŸ
    if face_region and 'bbox' in face_region:
        x, y, face_w, face_h = face_region['bbox']
        cv2.rectangle(debug_img, (x, y), (x + face_w, y + face_h), (255, 0, 0), 3)
        confidence = face_region.get('confidence', 0)
        cv2.putText(debug_img, f"Face ({confidence:.2f})", (x, y - 10),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)

        analysis_report.append(f"\né¢éƒ¨æ£€æµ‹:")
        analysis_report.append(f"  ä½ç½®: ({x}, {y})")
        analysis_report.append(f"  å°ºå¯¸: {face_w} x {face_h}")
        analysis_report.append(f"  ç½®ä¿¡åº¦: {confidence:.3f}")
        analysis_report.append(f"  å å›¾åƒæ¯”ä¾‹: {(face_w * face_h) / (w * h) * 100:.1f}%")
        analysis_report.append(f"  å®½é«˜æ¯”: {face_w / face_h:.2f}")
        analysis_report.append(f"  ä¸­å¿ƒä½ç½®: ({x + face_w//2}, {y + face_h//2})")
    else:
        analysis_report.append("\né¢éƒ¨æ£€æµ‹: å¤±è´¥")

    # æ ‡æ³¨é¢éƒ¨ç‰¹å¾
    colors = {
        'eyes': (0, 255, 0),
        'mouth': (0, 0, 255),
        'nose': (255, 255, 0),
        'eyebrows': (255, 0, 255)
    }

    analysis_report.append(f"\né¢éƒ¨ç‰¹å¾æ£€æµ‹:")

    for feature_name, feature_data in facial_features.items():
        color = colors.get(feature_name, (128, 128, 128))
        analysis_report.append(f"\n  {feature_name}:")

        if feature_name == 'eyes' and isinstance(feature_data, dict):
            for eye_name, eye_data in feature_data.items():
                if 'bbox' in eye_data:
                    x, y, w_eye, h_eye = eye_data['bbox']
                    cv2.rectangle(debug_img, (x, y), (x + w_eye, y + h_eye), color, 2)
                    cv2.putText(debug_img, eye_name, (x, y - 5),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)

                    analysis_report.append(f"    {eye_name}: ({x}, {y}) {w_eye}x{h_eye}")
                    analysis_report.append(f"      ä¸­å¿ƒ: ({x + w_eye//2}, {y + h_eye//2})")

        elif isinstance(feature_data, dict) and 'bbox' in feature_data:
            x, y, w_feat, h_feat = feature_data['bbox']
            cv2.rectangle(debug_img, (x, y), (x + w_feat, y + h_feat), color, 2)
            cv2.putText(debug_img, feature_name, (x, y - 5),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

            analysis_report.append(f"    ä½ç½®: ({x}, {y})")
            analysis_report.append(f"    å°ºå¯¸: {w_feat} x {h_feat}")
            analysis_report.append(f"    ä¸­å¿ƒ: ({x + w_feat//2}, {y + h_feat//2})")
        else:
            analysis_report.append(f"    æ£€æµ‹å¤±è´¥")

    # åˆ†æé¢œè‰²åˆ†å¸ƒ
    analysis_report.append(f"\né¢œè‰²åˆ†æ:")

    # è½¬æ¢åˆ°ä¸åŒè‰²å½©ç©ºé—´è¿›è¡Œåˆ†æ
    hsv = cv2.cvtColor(img_array, cv2.COLOR_RGB2HSV)
    lab = cv2.cvtColor(img_array, cv2.COLOR_RGB2LAB)

    # åˆ†æè‚¤è‰²åˆ†å¸ƒ
    skin_mask = detect_skin_regions(img_array)
    skin_percentage = np.sum(skin_mask > 0) / (w * h) * 100
    analysis_report.append(f"  è‚¤è‰²åŒºåŸŸå æ¯”: {skin_percentage:.1f}%")

    # åˆ†æäº®åº¦åˆ†å¸ƒ
    gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
    brightness_mean = np.mean(gray)
    brightness_std = np.std(gray)
    analysis_report.append(f"  å¹³å‡äº®åº¦: {brightness_mean:.1f}")
    analysis_report.append(f"  äº®åº¦æ ‡å‡†å·®: {brightness_std:.1f}")

    # åˆ†æå¯¹æ¯”åº¦
    contrast = brightness_std / brightness_mean if brightness_mean > 0 else 0
    analysis_report.append(f"  å¯¹æ¯”åº¦: {contrast:.3f}")

    # ä¿å­˜è°ƒè¯•å›¾åƒ
    debug_path = output_dir / "advanced_semantic_debug.png"
    Image.fromarray(debug_img).save(debug_path)
    print(f"ğŸ” é«˜çº§è¯­ä¹‰åˆ†æè°ƒè¯•å›¾åƒå·²ä¿å­˜: {debug_path}")

    # ä¿å­˜è‚¤è‰²æ£€æµ‹ç»“æœ
    skin_debug_img = img_array.copy()
    skin_debug_img[skin_mask == 0] = [128, 128, 128]  # éè‚¤è‰²åŒºåŸŸå˜ç°
    skin_debug_path = output_dir / "skin_detection_debug.png"
    Image.fromarray(skin_debug_img).save(skin_debug_path)
    print(f"ğŸ¨ è‚¤è‰²æ£€æµ‹è°ƒè¯•å›¾åƒå·²ä¿å­˜: {skin_debug_path}")

    # ä¿å­˜åˆ†ææŠ¥å‘Š
    report_path = output_dir / "semantic_analysis_report.txt"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write('\n'.join(analysis_report))
    print(f"ğŸ“Š è¯­ä¹‰åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_path}")

def detect_skin_regions(img_array):
    """æ£€æµ‹è‚¤è‰²åŒºåŸŸ"""
    hsv = cv2.cvtColor(img_array, cv2.COLOR_RGB2HSV)

    # å¤šç§è‚¤è‰²èŒƒå›´
    skin_ranges = [
        ([0, 20, 70], [20, 255, 255]),
        ([0, 25, 80], [25, 255, 255]),
        ([0, 30, 60], [30, 255, 200])
    ]

    combined_mask = np.zeros(img_array.shape[:2], dtype=np.uint8)

    for lower, upper in skin_ranges:
        lower = np.array(lower)
        upper = np.array(upper)
        mask = cv2.inRange(hsv, lower, upper)
        combined_mask = cv2.bitwise_or(combined_mask, mask)

    return combined_mask

def analyze_3d_mesh_structure(vertices, faces):
    """åˆ†æ3Dç½‘æ ¼ç»“æ„"""
    print("ğŸ” åˆ†æ3Dç½‘æ ¼ç»“æ„")

    center = vertices.mean(axis=0)
    centered = vertices - center

    # PCAåˆ†æ
    cov_matrix = np.cov(centered.T)
    eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)
    idx = np.argsort(eigenvalues)[::-1]
    eigenvalues = eigenvalues[idx]
    eigenvectors = eigenvectors[:, idx]

    # è®¡ç®—å„ç§å‡ ä½•ç‰¹å¾
    distances = np.linalg.norm(centered, axis=1)

    # æŠ•å½±åˆ°ä¸»è½´
    proj_x = np.dot(centered, eigenvectors[:, 0])
    proj_y = np.dot(centered, eigenvectors[:, 1])
    proj_z = np.dot(centered, eigenvectors[:, 2])

    # åˆ†æå½¢çŠ¶ç‰¹å¾
    aspect_ratios = eigenvalues / eigenvalues[0]

    # æ£€æµ‹å¯¹ç§°æ€§
    symmetry_score = analyze_symmetry(centered, eigenvectors)

    # åˆ†æé¡¶ç‚¹å¯†åº¦åˆ†å¸ƒ
    density_analysis = analyze_vertex_density(vertices, faces)

    # æ£€æµ‹çªå‡ºéƒ¨åˆ†ï¼ˆå¯èƒ½æ˜¯å››è‚¢ï¼‰
    protrusions = detect_protrusions(centered, distances)

    analysis = {
        'center': center,
        'eigenvalues': eigenvalues,
        'eigenvectors': eigenvectors,
        'aspect_ratios': aspect_ratios,
        'symmetry_score': symmetry_score,
        'density_analysis': density_analysis,
        'protrusions': protrusions,
        'vertex_count': len(vertices),
        'face_count': len(faces),
        'bounding_box': {
            'min': vertices.min(axis=0),
            'max': vertices.max(axis=0),
            'size': vertices.max(axis=0) - vertices.min(axis=0)
        }
    }

    return analysis

def analyze_symmetry(centered, eigenvectors):
    """åˆ†ææ¨¡å‹çš„å¯¹ç§°æ€§"""
    # ä½¿ç”¨ä¸»è½´ä½œä¸ºå¯¹ç§°è½´è¿›è¡Œåˆ†æ
    main_axis = eigenvectors[:, 0]

    # å°†é¡¶ç‚¹æŠ•å½±åˆ°å‚ç›´äºä¸»è½´çš„å¹³é¢
    proj_to_plane = centered - np.outer(np.dot(centered, main_axis), main_axis)

    # è®¡ç®—å¯¹ç§°æ€§å¾—åˆ†
    # ç®€å•æ–¹æ³•ï¼šæ¯”è¾ƒå·¦å³ä¸¤ä¾§çš„ç‚¹åˆ†å¸ƒ
    side_axis = eigenvectors[:, 1]
    side_proj = np.dot(proj_to_plane, side_axis)

    left_points = proj_to_plane[side_proj < 0]
    right_points = proj_to_plane[side_proj > 0]

    if len(left_points) > 0 and len(right_points) > 0:
        # è®¡ç®—å·¦å³ä¸¤ä¾§çš„åˆ†å¸ƒç›¸ä¼¼æ€§
        left_std = np.std(left_points, axis=0)
        right_std = np.std(right_points, axis=0)

        symmetry = 1.0 - np.mean(np.abs(left_std - right_std) / (left_std + right_std + 1e-8))
        return max(0, min(1, symmetry))

    return 0.5

def analyze_vertex_density(vertices, faces):
    """åˆ†æé¡¶ç‚¹å¯†åº¦åˆ†å¸ƒ"""
    # è®¡ç®—æ¯ä¸ªé¡¶ç‚¹çš„é‚»å±…æ•°é‡
    vertex_neighbors = [[] for _ in range(len(vertices))]

    for face in faces:
        for i in range(3):
            for j in range(3):
                if i != j:
                    vertex_neighbors[face[i]].append(face[j])

    neighbor_counts = [len(set(neighbors)) for neighbors in vertex_neighbors]

    return {
        'mean_neighbors': np.mean(neighbor_counts),
        'std_neighbors': np.std(neighbor_counts),
        'min_neighbors': np.min(neighbor_counts),
        'max_neighbors': np.max(neighbor_counts)
    }

def detect_protrusions(centered, distances):
    """æ£€æµ‹çªå‡ºéƒ¨åˆ†ï¼ˆå››è‚¢ç­‰ï¼‰"""
    # ä½¿ç”¨è·ç¦»é˜ˆå€¼æ£€æµ‹çªå‡ºéƒ¨åˆ†
    distance_threshold = np.percentile(distances, 85)  # å‰15%çš„è¿œç‚¹

    protrusion_mask = distances > distance_threshold
    protrusion_points = centered[protrusion_mask]

    if len(protrusion_points) == 0:
        return []

    # ä½¿ç”¨èšç±»åˆ†æå°†çªå‡ºç‚¹åˆ†ç»„
    from sklearn.cluster import DBSCAN

    clustering = DBSCAN(eps=0.1, min_samples=10).fit(protrusion_points)
    labels = clustering.labels_

    protrusions = []
    for label in set(labels):
        if label == -1:  # å™ªå£°ç‚¹
            continue

        cluster_points = protrusion_points[labels == label]
        cluster_center = cluster_points.mean(axis=0)
        cluster_size = len(cluster_points)

        protrusions.append({
            'center': cluster_center,
            'size': cluster_size,
            'points': cluster_points
        })

    return protrusions

def save_3d_mesh_analysis(mesh, analysis, output_dir):
    """ä¿å­˜3Dç½‘æ ¼åˆ†æç»“æœ"""
    print("ğŸ’¾ ä¿å­˜3Dç½‘æ ¼åˆ†æç»“æœ")

    report = []
    report.append("=== 3Dç½‘æ ¼ç»“æ„åˆ†ææŠ¥å‘Š ===")
    report.append(f"é¡¶ç‚¹æ•°é‡: {analysis['vertex_count']}")
    report.append(f"é¢æ•°é‡: {analysis['face_count']}")

    # è¾¹ç•Œæ¡†ä¿¡æ¯
    bbox = analysis['bounding_box']
    report.append(f"\nè¾¹ç•Œæ¡†:")
    report.append(f"  æœ€å°åæ ‡: ({bbox['min'][0]:.3f}, {bbox['min'][1]:.3f}, {bbox['min'][2]:.3f})")
    report.append(f"  æœ€å¤§åæ ‡: ({bbox['max'][0]:.3f}, {bbox['max'][1]:.3f}, {bbox['max'][2]:.3f})")
    report.append(f"  å°ºå¯¸: ({bbox['size'][0]:.3f}, {bbox['size'][1]:.3f}, {bbox['size'][2]:.3f})")

    # ä¸»è½´åˆ†æ
    report.append(f"\nä¸»è½´åˆ†æ:")
    eigenvalues = analysis['eigenvalues']
    eigenvectors = analysis['eigenvectors']
    aspect_ratios = analysis['aspect_ratios']

    for i, (val, vec, ratio) in enumerate(zip(eigenvalues, eigenvectors.T, aspect_ratios)):
        report.append(f"  ä¸»è½´{i+1}: ç‰¹å¾å€¼={val:.3f}, æ¯”ä¾‹={ratio:.3f}")
        report.append(f"    æ–¹å‘: ({vec[0]:.3f}, {vec[1]:.3f}, {vec[2]:.3f})")

    # å½¢çŠ¶åˆ†ç±»
    if aspect_ratios[1] > 0.7 and aspect_ratios[2] > 0.7:
        shape_type = "çƒå½¢"
    elif aspect_ratios[1] > 0.3 and aspect_ratios[2] < 0.3:
        shape_type = "æŸ±å½¢"
    elif aspect_ratios[2] < 0.2:
        shape_type = "æ‰å¹³å½¢"
    else:
        shape_type = "ä¸è§„åˆ™å½¢"

    report.append(f"\nå½¢çŠ¶åˆ†ç±»: {shape_type}")
    report.append(f"å¯¹ç§°æ€§å¾—åˆ†: {analysis['symmetry_score']:.3f}")

    # é¡¶ç‚¹å¯†åº¦åˆ†æ
    density = analysis['density_analysis']
    report.append(f"\né¡¶ç‚¹å¯†åº¦åˆ†æ:")
    report.append(f"  å¹³å‡é‚»å±…æ•°: {density['mean_neighbors']:.1f}")
    report.append(f"  é‚»å±…æ•°æ ‡å‡†å·®: {density['std_neighbors']:.1f}")
    report.append(f"  æœ€å°‘é‚»å±…æ•°: {density['min_neighbors']}")
    report.append(f"  æœ€å¤šé‚»å±…æ•°: {density['max_neighbors']}")

    # çªå‡ºéƒ¨åˆ†åˆ†æ
    protrusions = analysis['protrusions']
    report.append(f"\nçªå‡ºéƒ¨åˆ†æ£€æµ‹:")
    report.append(f"  æ£€æµ‹åˆ° {len(protrusions)} ä¸ªçªå‡ºéƒ¨åˆ†")

    for i, prot in enumerate(protrusions):
        center = prot['center']
        size = prot['size']
        report.append(f"  çªå‡ºéƒ¨åˆ†{i+1}: ä¸­å¿ƒ({center[0]:.3f}, {center[1]:.3f}, {center[2]:.3f}), å¤§å°={size}")

    # è¯­ä¹‰éƒ¨ä½æ¨æµ‹
    report.append(f"\nè¯­ä¹‰éƒ¨ä½æ¨æµ‹:")

    # åŸºäºå½¢çŠ¶å’Œçªå‡ºéƒ¨åˆ†æ¨æµ‹èº«ä½“éƒ¨ä½
    if len(protrusions) >= 4:
        report.append("  å¯èƒ½æ˜¯äººå½¢æˆ–åŠ¨ç‰©æ¨¡å‹ï¼ˆæ£€æµ‹åˆ°å¤šä¸ªçªå‡ºéƒ¨åˆ†ï¼‰")
        report.append("  çªå‡ºéƒ¨åˆ†å¯èƒ½å¯¹åº”ï¼šå››è‚¢ã€å¤´éƒ¨ç­‰")
    elif len(protrusions) >= 2:
        report.append("  å¯èƒ½æ˜¯ç®€åŒ–çš„äººå½¢æ¨¡å‹")
    else:
        report.append("  å¯èƒ½æ˜¯ç®€å•å‡ ä½•ä½“æˆ–å¤´éƒ¨æ¨¡å‹")

    if aspect_ratios[1] > 0.6:
        report.append("  æ¨¡å‹ç›¸å¯¹å¯¹ç§°ï¼Œé€‚åˆä½¿ç”¨å¯¹ç§°UVæ˜ å°„")
    else:
        report.append("  æ¨¡å‹ä¸å¯¹ç§°ï¼Œéœ€è¦ç‰¹æ®Šçš„UVæ˜ å°„ç­–ç•¥")

    # ä¿å­˜æŠ¥å‘Š
    report_path = output_dir / "3d_mesh_analysis_report.txt"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write('\n'.join(report))
    print(f"ğŸ“Š 3Dç½‘æ ¼åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_path}")

    # åˆ›å»ºå¯è§†åŒ–å›¾åƒ
    create_mesh_visualization(mesh, analysis, output_dir)

def create_mesh_visualization(mesh, analysis, output_dir):
    """åˆ›å»ºç½‘æ ¼å¯è§†åŒ–"""
    print("ğŸ¨ åˆ›å»ºç½‘æ ¼å¯è§†åŒ–")

    try:
        import matplotlib.pyplot as plt
        from mpl_toolkits.mplot3d import Axes3D

        vertices = mesh.vertices
        center = analysis['center']
        centered = vertices - center

        # åˆ›å»º3Dæ•£ç‚¹å›¾
        fig = plt.figure(figsize=(15, 5))

        # å­å›¾1ï¼šåŸå§‹ç½‘æ ¼
        ax1 = fig.add_subplot(131, projection='3d')
        ax1.scatter(vertices[:, 0], vertices[:, 1], vertices[:, 2],
                   c='blue', alpha=0.6, s=0.1)
        ax1.set_title('åŸå§‹ç½‘æ ¼')
        ax1.set_xlabel('X')
        ax1.set_ylabel('Y')
        ax1.set_zlabel('Z')

        # å­å›¾2ï¼šä¸»è½´åˆ†æ
        ax2 = fig.add_subplot(132, projection='3d')
        ax2.scatter(centered[:, 0], centered[:, 1], centered[:, 2],
                   c='gray', alpha=0.6, s=0.1)

        # ç»˜åˆ¶ä¸»è½´
        eigenvectors = analysis['eigenvectors']
        eigenvalues = analysis['eigenvalues']
        colors = ['red', 'green', 'blue']

        for i, (vec, val, color) in enumerate(zip(eigenvectors.T, eigenvalues, colors)):
            scale = np.sqrt(val) * 2
            ax2.quiver(0, 0, 0, vec[0]*scale, vec[1]*scale, vec[2]*scale,
                      color=color, arrow_length_ratio=0.1, linewidth=3,
                      label=f'ä¸»è½´{i+1}')

        ax2.set_title('ä¸»è½´åˆ†æ')
        ax2.set_xlabel('X')
        ax2.set_ylabel('Y')
        ax2.set_zlabel('Z')
        ax2.legend()

        # å­å›¾3ï¼šçªå‡ºéƒ¨åˆ†æ£€æµ‹
        ax3 = fig.add_subplot(133, projection='3d')
        ax3.scatter(centered[:, 0], centered[:, 1], centered[:, 2],
                   c='lightgray', alpha=0.3, s=0.1)

        # æ ‡æ³¨çªå‡ºéƒ¨åˆ†
        protrusions = analysis['protrusions']
        colors_prot = plt.cm.Set1(np.linspace(0, 1, len(protrusions)))

        for i, (prot, color) in enumerate(zip(protrusions, colors_prot)):
            points = prot['points']
            center_prot = prot['center']

            ax3.scatter(points[:, 0], points[:, 1], points[:, 2],
                       c=[color], alpha=0.8, s=2, label=f'çªå‡ºéƒ¨åˆ†{i+1}')
            ax3.scatter([center_prot[0]], [center_prot[1]], [center_prot[2]],
                       c='black', s=50, marker='x')

        ax3.set_title('çªå‡ºéƒ¨åˆ†æ£€æµ‹')
        ax3.set_xlabel('X')
        ax3.set_ylabel('Y')
        ax3.set_zlabel('Z')
        if len(protrusions) > 0:
            ax3.legend()

        plt.tight_layout()

        # ä¿å­˜å¯è§†åŒ–
        viz_path = output_dir / "mesh_analysis_visualization.png"
        plt.savefig(viz_path, dpi=150, bbox_inches='tight')
        plt.close()

        print(f"ğŸ“Š ç½‘æ ¼åˆ†æå¯è§†åŒ–å·²ä¿å­˜: {viz_path}")

    except ImportError:
        print("âš ï¸ matplotlibæœªå®‰è£…ï¼Œè·³è¿‡å¯è§†åŒ–")
    except Exception as e:
        print(f"âš ï¸ åˆ›å»ºå¯è§†åŒ–æ—¶å‡ºé”™: {e}")

if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
